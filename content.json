{"meta":{"title":"暗语者的博客","subtitle":null,"description":"没有最好的语言, 只有最适合你开发场景的语言","author":"暗语者","url":"https://anyuzhe.github.io","root":"/"},"pages":[{"title":"tags","date":"2019-09-06T06:54:43.000Z","updated":"2021-11-19T03:41:15.358Z","comments":false,"path":"tags/index.html","permalink":"https://anyuzhe.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-09-06T06:56:13.000Z","updated":"2021-11-19T03:41:15.358Z","comments":false,"path":"categories/index.html","permalink":"https://anyuzhe.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"moodle功能整理","slug":"moodle功能整理","date":"2019-10-13T09:01:55.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2019/10/13/moodle功能整理/","link":"","permalink":"https://anyuzhe.github.io/2019/10/13/moodle功能整理/","excerpt":"","text":"介绍Moodle是一个学习管理系统（LMS，也叫VLE） Moodle是由模块化（Modular）面向（Oriented）对象（Obeject）的动态（Dynamic）学习 （Learning）环境（Environment）的首字母缩写组成 主要功能课程管理课程分类默认由管理员管理可以在权限设置里设置，权限分配给角色 分类设置里可以设置各种关联，有： 角色，群组，学历模板，能力框架关联的效果待测试 课程格式（类型）单一活动格式只能设置一种活动格式 IMS内容包 IMS是一个为各种内容，包括e-learning材料，界定技术标准的团体。IMS内容包规范可以使得材料组块以标准的形式来存储，而这种标准形式能够在不同系统中重复使用，而无需将材料转换为新的形式。 Moodle中的IMS内容包使得这种内容包能够在Moodle课程中上传和使用。Moodle中可以有各种选项来显示内容、导航或按钮等。 SCORM课件 SCORM模块允许教师将任何SCORM包或AICC包上传到自己的课程中。 Moodle支持SCORM1.2但不支持SCORM2004，请浏览SCORM常见问题中的supported versions 获取更多信息。 SCORM（Sharable Content Object Reference Model）是一个技术规范集，旨在促使web学习内容具有互操作性、可获得性和可再次使用性。SCORM内容可以通过任何一个兼容SCORM的学习管理系统（LMS）来传输给学习者（使用相同版本的SCORM）。 Wiki协作 测验 测验考试功能 程序教学 词汇表 反馈 互动评价 聊天 类似一个qq群聊 数据库 讨论区 类似一个论坛 投票 图书 外部工具 网页 网页地址 文件 文件夹 问卷调查 作业 社区格式设定话题数量 可以开启话题话题类似于一个微信中的一条朋友圈，别人可以在下面回复回复的高级模式是富文本框 可以包含文件图片等等 主题格式由多个主题组成每个主题下面可以添加多个活动或者资源默认有一个名为新闻通告的主题，里面有一个讨论区的活动 星期格式设定章节数量章节名是类似“10月13日 - 10月19日”的一周时间章节与主题相似，每个章节下面可以添加多个活动或者资源默认有一个名为新闻通告的主题，里面有一个讨论区的活动 其他组选项，重命名角色 权限管理默认角色有管理员，课程创建者，已认证用户，访客，教师，无边际权教师，学生 用户管理可以追加字段，类型有： 复选框 文本域 文本 日期 选择菜单 可以批量处理： 强制修改密码 添加到群 发消息 删除 成绩管理可以设置参数，等级，分数段 分析设置能力管理能力框架 -&gt; 能力 能力框架里可以设置等级 学习模板 -&gt; 能力 -&gt; 课程 可以用学历模板给用户添加学习计划可以把课程推给学生 勋章设置位置语言消息安全插件管理外观主题设置图标设置日历设置博客设置导航设置HTML设置Moodle文档默认个人主页缺省个人资料页课程AJAX和JavaScript管理标签附加的HTML用户导航 首页设置网站信息，导航栏按钮， 服务器 系统路径 技术支持会话处理HTTP维护模式清理环境PHP 信息性能Tasks电子邮件 报表移动应用程序开发","categories":[{"name":"项目整理文档","slug":"项目整理文档","permalink":"https://anyuzhe.github.io/categories/项目整理文档/"}],"tags":[{"name":"moodle","slug":"moodle","permalink":"https://anyuzhe.github.io/tags/moodle/"}]},{"title":"SpringBoot相关记录","slug":"SpringBoot相关记录","date":"2019-10-13T09:01:55.000Z","updated":"2021-11-19T03:51:34.106Z","comments":true,"path":"2019/10/13/SpringBoot相关记录/","link":"","permalink":"https://anyuzhe.github.io/2019/10/13/SpringBoot相关记录/","excerpt":"","text":"最近经常被读者问到有没有 Spring Boot 实战项目可以学习，于是，我就去 Github 上找了 10 个我觉得还不错的实战项目。对于这些实战项目，有部分是比较适合 Spring Boot 刚入门的朋友学习的，还有一部分可能要求你对 Spring Boot 相关技术比较熟悉。需要的朋友可以根据个人实际情况进行选择。如果你对 Spring Boot 不太熟悉的话，可以看我最近开源的 springboot-guide：github.com/Snailclimb/… 入门（还在持续更新中）。 mall123Github地址： github.com/macrozheng/…star: 22.9k介绍: mall项目是一套电商系统，包括前台商城系统及后台管理系统，基于SpringBoot+MyBatis实现。 前台商城系统包含首页门户、商品推荐、商品搜索、商品展示、购物车、订单流程、会员中心、客户服务、帮助中心等模块。 后台管理系统包含商品管理、订单管理、会员管理、促销管理、运营管理、内容管理、统计报表、财务管理、权限管理、设置等模块。 jeecg-boot123Github地址：github.com/zhangdaisco…star: 6.4k介绍: 一款基于代码生成器的JAVA快速开发平台！采用最新技术，前后端分离架构：SpringBoot 2.x，Ant Design&amp;Vue，Mybatis，Shiro，JWT。强大的代码生成器让前后端代码一键生成，无需写任何代码，绝对是全栈开发福音！！ JeecgBoot的宗旨是提高UI能力的同时,降低前后分离的开发成本，JeecgBoot还独创在线开发模式，No代码概念，一系列在线智能开发：在线配置表单、在线配置报表、在线设计流程等等。 eladmin123Github地址：github.com/elunez/elad…star: 3.9k介绍: 项目基于 Spring Boot 2.1.0 、 Jpa、 Spring Security、redis、Vue的前后端分离的后台管理系统，项目采用分模块开发方式， 权限控制采用 RBAC，支持数据字典与数据权限管理，支持一键生成前后端代码，支持动态路由。 paascloud-master123Github地址：github.com/paascloud/p…star: 5.9k介绍: spring cloud + vue + oAuth2.0全家桶实战，前后端分离模拟商城，完整的购物流程、后端运营平台，可以实现快速搭建企业级微服务项目。支持微信登录等三方登录。 vhr123Github地址：github.com/lenve/vhrstar: 10.6k介绍: 微人事是一个前后端分离的人力资源管理系统，项目采用SpringBoot+Vue开发。 One mall123Github地址：github.com/YunaiV/onem…star: 1.2k介绍: mall 商城，基于微服务的思想，构建在 B2C 电商场景下的项目实战。核心技术栈，是 Spring Boot + Dubbo 。未来，会重构成 Spring Cloud Alibaba 。 Guns123Github地址：github.com/stylefeng/G…star: 2.3k介绍: Guns基于SpringBoot 2，致力于做更简洁的后台管理系统，完美整合springmvc + shiro + mybatis-plus + beetl!Guns项目代码简洁，注释丰富，上手容易，同时Guns包含许多基础模块(用户管理，角色管理，部门管理，字典管理等10个模块)，可以直接作为一个后台管理系统的脚手架! SpringCloud123Github地址：github.com/YunaiV/onem…star: 1.2k介绍: mall 商城，基于微服务的思想，构建在 B2C 电商场景下的项目实战。核心技术栈，是 Spring Boot + Dubbo 。未来，会重构成 Spring Cloud Alibaba 。 SpringBoot-Shiro-Vue123Github地址：github.com/Heeexy/Spri…star: 1.8k介绍: 提供一套基于Spring Boot-Shiro-Vue的权限管理思路.前后端都加以控制,做到按钮/接口级别的权限。 newbee-mall12345最近开源的一个商城项目。Github地址：github.com/newbee-ltd/…star: 50介绍: newbee-mall 项目是一套电商系统，包括 newbee-mall 商城系统及 newbee-mall-admin 商城后台管理系统，基于 Spring Boot 2.X 及相关技术栈开发。 前台商城系统包含首页门户、商品分类、新品上线、首页轮播、商品推荐、商品搜索、商品展示、购物车、订单结算、订单流程、个人订单管理、会员中心、帮助中心等模块。 后台管理系统包含数据面板、轮播图管理、商品管理、订单管理、会员管理、分类管理、设置等模块。 作者的其他开源项目推荐 springboot-guide : 适合新手入门以及有经验的开发人员查阅的 Spring Boot 教程（业余时间维护中，欢迎一起维护）。programmer-advancement : 我觉得技术人员应该有的一些好习惯！spring-security-jwt-guide :从零入门 ！Spring Security With JWT（含权限验证）后端部分代码。 作者：SnailClimb链接：https://juejin.im/post/5da3c3dce51d4578034d2dc3来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/tags/java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://anyuzhe.github.io/tags/SpringBoot/"}]},{"title":"windows环境安装","slug":"windows环境安装","date":"2019-10-07T06:18:22.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2019/10/07/windows环境安装/","link":"","permalink":"https://anyuzhe.github.io/2019/10/07/windows环境安装/","excerpt":"","text":"windows开发环境安装php环境1.集成环境寻找了一下现有的windows集成环境 wsl子系统 与虚拟机方案等等个人觉得最佳方案是直接使用集成环境 laragon 优先是绿色，方便，强大 整个环境在一个文件夹下 包括服务也是没有用到windows的服务去启动 环境变量假如启动laragon自带的命令行 则已经配置了该有的 比如git, node, composer等基本工具 简单来说整个文件夹拷到另外一个电脑上 应该可以无缝使用 除了项目代码可能没有环境文件夹下，需要配置一下 安装教程or 安装教程 文件夹目录结构 目标 备注 bin 放置一些集成软件 data 存放数据文件目录 etc 配置文件目录 tmp 临时文件目录 usr laragon 核心资源目录 www 网站根目录 可以把bin里面用得到的软件的执行目录加到系统环境变量PATH中(php,node,composer,git) 简单介绍添加额外的PHP版本Laragon默认只包含一个PHP，如果需要多个PHP版本支持。 前往PHP官网 下载需要的PHP版本 然后解压到laragon\\bin\\php目录即可 将新增的php内部的php.ini-development改名为php.ini,并且进入当前php.ini中，修改extension_dir 为extension_dir = “C:/laragon2/bin/php/php-7.1.10-nts/ext”（按自己路径修改） 最后在Laragon - PHP选项，切换需要使用的PHP版本 Laragon打包Laragon不使用Windows服务，它有自己的service orchestration异步和非阻塞管理服务，因此您可以将Laragon目录压缩打包，然后直接解压到其它电脑就可以直接打开使用，就是这么方便。 2.开发工具 phpstorm最好用的php开发IDE，没有之一安装与使用省略 tips phpstorm可以开terminal，然后php -S localhost:8000 -t .\\public,还有laravel也要用到很多命令行php artisan phpstorm可以配置git，配好了之后ctrl+K，直接就填commit就好了，然后直接点击push phpstorm格式化代码的快捷键是alt+ctrl+L，这个主要是psr1，psr2的代码规范，psr2里很多就是空格规范，反正这个快捷键会让代码变好看。一整个页面就ctrl+A，然后alt+ctrl+L。 phpstrom里批量替换是crtl+R，这个快捷键在修改命名空间的时候很好用。 行操作里，crtl+D是复制一行，crtl+Y或者ctrl+X是删除一行，ctrl+X删除完了还可以直接粘贴，然后shift+ctrl+up/dowm是单行代码移动到上一行或下一行 ctrl+鼠标左键单击，直接就跳到鼠标停留处那个类的文件去啦，一层层的翻，你会发现慢慢就到底层代码啦，虽然一脸懵看不懂，但是慢慢来，假如有9层的话，你在第一层，跳到第2层，你就会觉得很神奇，这时候第2层都可能还不太会用，但是真的，只要多点几次，可能有一天，你会发现第4层，第5层你都用的66啦 查找文件，ctrl+F是单文件内查找，phpstorm里还有查找类名，在phpstorm左上角有个navigate，点一下，然后选择class，file，symbol，这个也是查找。 phpstorm左侧的tool buttons很棒诶，projects是项目目录，structure是文件内结构，如果是面向过程，有很多function，这个就很有用啦。说起来右侧的datebase也配过，还是习惯用navicat(win)/dbeaver(linux).","categories":[{"name":"windows","slug":"windows","permalink":"https://anyuzhe.github.io/categories/windows/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"},{"name":"windows","slug":"windows","permalink":"https://anyuzhe.github.io/tags/windows/"}]},{"title":"hexo相关教程","slug":"hexo相关教程","date":"2019-09-12T05:55:02.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2019/09/12/hexo相关教程/","link":"","permalink":"https://anyuzhe.github.io/2019/09/12/hexo相关教程/","excerpt":"","text":"hexo使用教程 文章示例123456789---title: postName #文章页面上的显示名称，一般是中文date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文 next主题相关教程next文档 next添加Valine评论功能 为NexT主题添加文章阅读量统计功能 Hexo-Next主题解决统计访客人数功能失效 给基于HEXO的博客添加gitter在线交流 Hexo博客NexT主题右上角添加fork_me_on_github入口","categories":[{"name":"hexo","slug":"hexo","permalink":"https://anyuzhe.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://anyuzhe.github.io/tags/hexo/"}]},{"title":"Laravel，PHP 如何使用数据库连接池提高性能","slug":"Laravel-PHP-如何使用数据库连接池提高性能","date":"2019-06-10T01:17:34.000Z","updated":"2021-11-19T03:41:15.350Z","comments":true,"path":"2019/06/10/Laravel-PHP-如何使用数据库连接池提高性能/","link":"","permalink":"https://anyuzhe.github.io/2019/06/10/Laravel-PHP-如何使用数据库连接池提高性能/","excerpt":"","text":"数据库连接池 数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个；释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。这项技术能明显提高对数据库操作的性能。需要 PHP 7.0+ SWOOLE 2.1+ SMProxy Laravel MySQL 安装 swoole pecl install swoole 安装 SMProxy（推荐）直接下载最新发行版的 PHAR 文件，解压即用：1下载前两个压缩包中的一个或者使用 Git 切换任意版本：2git clone https://github.com/louislivi/smproxy.gitcomposer install –no-dev # 如果你想贡献你的代码，请不要使用 –no-dev 参数。 配置数据库连接池 假设 MySQL 数据库账号为 root 密码为 654321 库名为 test编辑 SMProxy 的 conf/database.json 文件 { “database”: { “account”: { “root”: { “user”: “root”,//数据库账号 “password”: “654321”//数据库密码 } }, “serverInfo”: { “server1”: { “write”: {//写库 “host”: “127.0.0.1”,//数据库地址 “port”: 3306, “timeout”: 0.5,//连接超时时间 “flag”: 0, “account”: “root” }, “read”: {//读库，没有可删掉read列 或填写与写库数据一致内容 “host”: “127.0.0.1”, “port”: 3306, “timeout”: 0.5, “flag”: 0, “account”: “root” } }, “databases”: { “test”: { “serverInfo”: “server1”, “startConns”: “swoole_cpu_num()10”, “maxSpareConns”: “swoole_cpu_num()10”, “maxSpareExp”: 3600, “maxConns”: “swoole_cpu_num()*20”, “charset”: “utf-8” } } }} 随后配置 SMProxy 的账号密码 在 conf/server.json 文件 { “server”: { “user”: “SMProxy”, //SMProxy账号 “password”: “SMProxy”, //SMProxy密码 “charset”: “utf8mb4”, “host”: “0.0.0.0”, “port”: “3366”, “mode”: “SWOOLE_PROCESS”, “sock_type”: “SWOOLE_SOCK_TCP”, “logs”: { “open”:true, “config”: { “system”: { “log_path”: “ROOT/logs”, “log_file”: “system.log”, “format”: “Y/m/d” }, “mysql”: { “log_path”: “ROOT/logs”, “log_file”: “mysql.log”, “format”: “Y/m/d” } } }, “swoole”: { “worker_num”: “swoole_cpu_num()”, “max_coro_num”: 6000, “open_tcp_nodelay”: true, “daemonize”: true, “heartbeat_check_interval”: 60, “heartbeat_idle_time”: 600, “reload_async”: true, “log_file”: “ROOT/logs/swoole.log”, “pid_file”: “ROOT/logs/pid/server.pid” }, “swoole_client_setting”: { “package_max_length”: 16777216 }, “swoole_client_sock_setting”: { “sock_type”: “SWOOLE_SOCK_TCP” } }} 启动 SMProxy 服务 ./SMProxy start配置 Laravel 数据库信息 .env 文件 DB_CONNECTION=mysqlDB_HOST=127.0.0.1DB_PORT=3366DB_DATABASE=testDB_USERNAME=SMProxyDB_PASSWORD=SMProxy SMProxy 文档https://smproxy.louislivi.com/#/","categories":[{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/categories/mysql/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"},{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/tags/mysql/"}]},{"title":"轻松全站 HTTPS","slug":"轻松全站HTTPS","date":"2018-11-09T02:46:34.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2018/11/09/轻松全站HTTPS/","link":"","permalink":"https://anyuzhe.github.io/2018/11/09/轻松全站HTTPS/","excerpt":"","text":"原文件地址：https://www.jianshu.com/p/57e5bb1277ce前言 注意：上 HTTPS 超级简单，写这么多，只是因为过程比较有趣，就多哆嗦了几句有了自己的博客：《极简博客搭建，搭建超级简单又好看》有了自己的图片处理服务：《搭建自己的图片处理服务 — 智能裁剪、旋转、占位一站搞定》都已经这么完美了，为什么还会有这篇文章呢？是对社会有什么不满意吗？HTTPS为什么要上 HTTPS 安全：你与用户之间的消息加密传输，防止中间人攻击(就是我遇到的问题)其它优点：当你在国内使用域名时，需要备案。有时你想测试一下你的站，用上未备案的域名，怎么办呢？https 可以帮你暂时绕过阿里云弹的未备案页(强烈建议去备案你的域名，一来你应当守法，二来未备案国内 cdn、网站收录什么的都需要备案的域名)，其它暂时没想到有什么优点。因果 前些天刚搭了个漂亮的小博客，写了几篇小日记还没有修改成小说。可以说非常开心了，于是今天早早洗完澡准备在床上用手机体验下网站自适应的效果。打开微信，扫了下自己站的二维码，顺势躺在床上。划～划～划，突然底部跳出一个广告，咦？什么情况？我什么时候投的广告？？这博客不会这么坑吧？竟然自带广告。不行，得起来撸代码了。带着懊恼的心情，我又回到了电脑前，开始检查博客的源码，看看具体哪里出了这个问题。看了一遍，没有问题。突然想到，这可能是被运营商劫持了。那没办法了，只能连夜上个 HTTPS 了。 准备 域名（自备） acme.sh acme.sh 是一个自动申请 https 证书的脚本，使用方便，功能也非常强大。 安装： curl https://get.acme.sh | sh 或者 wget -O - https://get.acme.sh | sh 这样你已经把 acme.sh 这个小工具安装到你本地的 ~/.acme.sh/中了，而不会在你系统的其它地方装些乱七八糟的东西。极速开始 不是阿里的朋友，可以尝试下面的常规路线阿里云购买域名的朋友可以走这个极速通道，因为阿里云有接口可以直接操作域名控制台，这个接口已经被整合到了 acme.sh 这个工具里面。只要设置一下 Ali_Key 和 Ali_Secret， 从哪里获得？ 在你的命令行中执行如下命令： export Ali_Key=&quot;换成你的 AccessKey ID&quot; export Ali_Secret=&quot;换成你的 Access Key Secret&quot; 开始申请证书 acme.sh --issue --dns dns_ali -d 2td.cc -d &apos;*.2td.cc&apos; 2td.cc 是我的域名，这里需要换成你的。 参数解释: acme.sh ：表示使用你刚安装好的acme.sh --issue ：申请证书 --dns dns_ali：使用阿里云的 dns 服务，在阿里云买的域名，在没有修改默认 dns 的前提下，都可以使用这个参数来申请 https 证书。 -d 2td.cc：-d表示 domain，后面跟你要申请域名。 -d &apos;*.2td.cc&apos;：这里的-d 与上方一样，-d 参数可以带多个，这里的&apos;*.2td.cc&apos;中的 * 表示泛域名，只要申请了这个证书像（www.2td.cc，mail.2td.cc，h5.2td.cc ...）这类的二级域名都可以使用此证书来实现 https。注意 2td.cc这个域名不在这条规则里，所以上面又加了一条-d 2td.cc，这样你的主域名、二级子域名均可以使用此证书。 等待执行完成，期间会有 120 秒的倒计时，结束后如果显示成功，则证书申请成功。 申请中… 申请完成 申请好的证书路径 应用到 nginx 修改你 nginx 的配置，配置 https server { listen 443 ssl; # 有了 https 可以尝试开启 http2，加速你的网站 # http2 需要你 nginx 加载了 http2 模块，用如下配置开启。 # listen 443 ssl http2; server_name 2td.cc; ssl_certificate /root/.acme.sh/2td.cc/fullchain.cer; ssl_certificate_key /root/.acme.sh/2td.cc/2td.cc.key; # charset koi8-r; access_log /var/log/nginx/host.access.log main; # 下面写你之前的配置 }常规路线 一些 DNS 服务商，没有提供 API 操作 DNS 的接口，所以整合不进这个工具里。当然我们也还是可以申请证书。这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。 申请证书 acme.sh –issue –dns -d aiwdh.cn –yes-I-know-dns-manual-mode-enough-go-ahead-please aiwdh.cn 是我的域名，这里需要换成你的。 参数解释: acme.sh ：表示使用你刚安装好的acme.sh –issue ：申请证书 –dns：使用 DNS 的方式来验证你的所有权，你需要在域名上添加一条 txt 解析记录, 验证域名所有权。 -d aiwdh.cn：-d表示 domain，后面跟你要申请域名。 –yes-I-know-dns-manual-mode-enough-go-ahead-please:官方不推荐使用此方式来生成证书，所以有这个额外的参数来提醒你你在做什么。 申请证书 添加 txt 记录 添加 txt 记录 加好记录后，重新申请证书 acme.sh –issue –dns -d aiwdh.cn –yes-I-know-dns-manual-mode-enough-go-ahead-please –renew 重新申请证书 申请好的证书路径 应用到 nginx 修改你 nginx 的配置，配置 https server { listen 443 ssl; # 有了 https 可以尝试开启 http2，加速你的网站 # http2 需要你 nginx 加载了 http2 模块，用如下配置开启。 # listen 443 ssl http2; server_name aiwdh.cn; ssl_certificate /root/.acme.sh/aiwdh.cn/fullchain.cer; ssl_certificate_key /root/.acme.sh/aiwdh.cn/aiwdh.cn.key; # charset koi8-r; access_log /var/log/nginx/host.access.log main; # 下面写你之前的配置 } 这种方式添加的证书，每当证书快过期，需要重新走一下这些步骤，稍微麻烦一点。结语 如果用极速申请的方式，很快就可以实现全站 https 了。当然第二种方式来申请证书你都不需要在自己的服务器上作操作，你可以在本地完成申请，把证书拿到各个地方去用。 终于用上了 https, 再也没有多余的广告在我手机上显示了，开心。申请速度倒是很快，整理不易，且行且珍惜。还没服务器域名？ 来参加阿里云双 11 底价团，12 号前 99.5/台起！","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"},{"name":"computer","slug":"computer","permalink":"https://anyuzhe.github.io/tags/computer/"}]},{"title":"socket 相关备份","slug":"socket_copy","date":"2018-09-26T07:23:26.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2018/09/26/socket_copy/","link":"","permalink":"https://anyuzhe.github.io/2018/09/26/socket_copy/","excerpt":"","text":"phpsocket.ioWorkerman github laravel-echo-server","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"css 文档归总","slug":"css文档","date":"2018-08-22T02:13:46.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2018/08/22/css文档/","link":"","permalink":"https://anyuzhe.github.io/2018/08/22/css文档/","excerpt":"","text":"本文档是《层叠样式表2级修订版1（CSS 2.1）规范（W3C推荐2011-06-07）》的简体中文翻译。 css参考 CSS 选择器","categories":[{"name":"vue","slug":"vue","permalink":"https://anyuzhe.github.io/categories/vue/"}],"tags":[{"name":"css","slug":"css","permalink":"https://anyuzhe.github.io/tags/css/"}]},{"title":"Pandas速查手册","slug":"Pandas速查手册","date":"2018-05-09T14:45:31.000Z","updated":"2021-11-19T03:41:15.350Z","comments":true,"path":"2018/05/09/Pandas速查手册/","link":"","permalink":"https://anyuzhe.github.io/2018/05/09/Pandas速查手册/","excerpt":"","text":"","categories":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/tags/python/"}]},{"title":"http详解","slug":"http详解","date":"2018-03-07T10:43:06.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2018/03/07/http详解/","link":"","permalink":"https://anyuzhe.github.io/2018/03/07/http详解/","excerpt":"","text":"","categories":[{"name":"后端基础","slug":"后端基础","permalink":"https://anyuzhe.github.io/categories/后端基础/"}],"tags":[{"name":"temp","slug":"temp","permalink":"https://anyuzhe.github.io/tags/temp/"}]},{"title":"php+apache 和 php+nginx的区别","slug":"php+apache-和-php+nginx的区别","date":"2018-03-07T10:27:32.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2018/03/07/php+apache-和-php+nginx的区别/","link":"","permalink":"https://anyuzhe.github.io/2018/03/07/php+apache-和-php+nginx的区别/","excerpt":"","text":"php+apache 和 php+nginx的区别 性能好只是 IO 性能好。而 Apache 的 CPU 性能更好。 apache是通过mod_php来解析php nginx是通过php-fpm(fast-cgi)来解析php PHP 解释器是否嵌入 Web 服务器进程内部执行 mod_php 通过嵌入 PHP 解释器到 Apache 进程中，只能与 Apache 配合使用，而 cgi 和 fast-cgi 以独立的进程的形式出现，只要对应的Web服务器实现 cgi 或者 fast-cgi 协议，就能够处理 PHP 请求。 mod_php 这种嵌入的方式最大的弊端就是内存占用大，不论是否用到 PHP 解释器都会将其加载到内存中，典型的就是处理CSS、JS之类的静态文件是完全没有必要加载解释器。 单个进程处理的请求数量 mod_php 和 fast-cgi 的模式在每个进程的生命周期内能够处理多个请求(fast-cgi可以根据需要来调整进程的多少)，而 cgi 的模式处理一个请求就马上销毁进程，在高并发的场景下 cgi 的性能非常糟糕。 每一个Web请求PHP都必须重新解析php.ini、重新载入全部dll扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次 综上，如果对性能有极高的要求，可以将静态请求和动态请求分开，这时 Nginx + php-fpm 是比较好的选择。 PS: cgi、fastcgi 通常指 Web 服务器与解释器通信的协议规范，而 php-fpm 是 fastcgi 协议的一个实现。","categories":[{"name":"后端基础","slug":"后端基础","permalink":"https://anyuzhe.github.io/categories/后端基础/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"mod_php、FastCGI、PHP-FPM等PHP运行方式对比","slug":"temp222","date":"2018-03-07T10:24:36.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2018/03/07/temp222/","link":"","permalink":"https://anyuzhe.github.io/2018/03/07/temp222/","excerpt":"","text":"mod_php、FastCGI、PHP-FPM等PHP运行方式对比 写这篇文章的是因为今天要Ubuntu下搭建LNMP环境，Nginx使用的是PHP-FPM，所以对Web服务器与PHP解释器的交互方式做了个整理。 众所周知，PHP是跨平台、跨服务器的语言，这也是它如此流行的原因之一。但是，很少有人知道PHP解释器可以以不同的方式运行在Web服务器中。PHP最常用的方式是以模块的方式(mod_php)运行在Apache中，也是Apache运行PHP的默认方式。但是在Nginx中，Nginx又使用的是PHP-FPM。 这篇文章就对这些概念做个介绍，如有不对的地方，请多多批评指教。 什么是PHP处理器(PHP handlers)？ 首先需要记住的是，任何一种Web服务器(Apache、Nginx等)都是被设计成向用户发送html、图片等静态资源的，Web服务器自身并不能解释任何动态脚本(PHP、Python等)。PHP处理器就是用来解释Web应用中的PHP代码，并将它解释为HTML或其他静态资源，然后将解析的结果传给Web服务器，最后再由Web服务器发送给用户。大多数的Web服务器都不能解析PHP代码，因此它需要一个能解析PHP代码的程序，这就是PHP处理器。 mod_php 首先，来看一下以Apache模块方式运行PHP。mod_php现在在Linux各版本的软件仓库里都有，因此很容易被安装。 当PHP以模块的方式运行在Apache中时，PHP解释器被“内嵌”在Apache的进程里。Apache不会调用任何外部的PHP进程，因此这种方式使Apache与PHP能更好的通信。但是，当以这种方式运行PHP的时候，哪怕Apache提供的仅仅是静态的资源(如HTML)，Apache的每个子进程也都会载入 mod_php，导致了比正常情况下更多的内存开销。 以这种方式运行的另一个缺点是，它仅能与Apache一起配合工作。另外，在小型的VPS和大型的网站中，这种方式也不合适，因为大型网站可能有很多静态资源，而这些静态资源是不需要PHP程序解释的。 优点:1.易于安装和更新2.容配置缺点:1.仅能与Apache一起工作2.增加了Apache子进程内存开销3.当更改php.ini文件后，需要重启Apache FastCGI FastCGI是交互程序与Web服务器通用的协议接口，是早期CGI(Common Gateway Interface)的一个变种。相对于CGI来说，FastCGI减少了和Web服务器交互的开销，同时一次可以处理更多的请求。 Apache可以以mod_fcgid的形式使用FastCGI。其他Web服务器，如lighttpd, nginx, Cherokee，甚至微软的IIS也都能使用FastCGI。使用FastCGI，可以同时设置多个版本的PHP，这在某些情况下非常有用。 FastCGI还利用suexec来支持不同的用户用自己的PHP的实例。这个特性对于在共享环境下提高安全性尤其重要。FastCGI在保证性能的同时，也减少了Web服务器的内存开销。 优点:1.兼容多数Web服务器2.比mod_php占内存小3.更多的配置项，包括多版本PHP和suexec缺点1.配置复杂2.不被大家所熟知 PHP-FPM(FastCGI Process Manager) PHP-FPM是Web服务器使用PHP的一种最新方式，也是PHP FastCGI的另外一种实现。PHP-FPM对于运行在小型VPS和多服务器上的Web应用非常应用。同时，它也可以被兼容FastCGI的任何Web服务器所使用。 PHP-FPM使管理员能够优雅地停止和启动PHP工作进程而不丢失任何查询。这允许我们逐步更新配置和二进制,而不会损失任何查询。它还允许我们在发生任何意外破坏的情况下，紧急重启进程。 优点:1.兼容多数Web服务器2.比mod_php占内存小3.更多的配置项，包括多版本PHP和suexec缺点1.配置复杂2.不被大家所熟知 补充:Apache运行PHP的四种方式 mod_php (DSO，Dynamic Shared Object)CGIsuPHPFastCGI","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://anyuzhe.github.io/categories/计算机基础/"}],"tags":[{"name":"temp","slug":"temp","permalink":"https://anyuzhe.github.io/tags/temp/"}]},{"title":"nginx 基本配置与参数说明（转）","slug":"nginx-基本配置与参数说明","date":"2018-01-29T15:13:28.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2018/01/29/nginx-基本配置与参数说明/","link":"","permalink":"https://anyuzhe.github.io/2018/01/29/nginx-基本配置与参数说明/","excerpt":"","text":"#运行用户user nobody; #启动进程,通常设置成和cpu的数量相等worker_processes 1; #全局错误日志及PID文件 #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; #工作模式及连接数上限events { #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535 } http { #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main ‘$remote_addr - $remote_user [$time_local] “$request” ‘ ‘$status $body_bytes_sent “$http_referer” ‘ ‘“$http_user_agent” “$http_x_forwarded_for”‘; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable “MSIE [1-6].”; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #设定虚拟主机配置 server { #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / { #定义首页索引文件的名称 index index.php index.html index.htm; } # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html { } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; } #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } #禁止访问 .htxxx 文件 location ~ /.ht { deny all; } } }","categories":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/tags/nginx/"}]},{"title":"nginx https 配置","slug":"nginx_https","date":"2017-10-26T01:17:50.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2017/10/26/nginx_https/","link":"","permalink":"https://anyuzhe.github.io/2017/10/26/nginx_https/","excerpt":"","text":"server { listen 443; server_name www.domain.com; #填写绑定证书的域名 ssl on; ssl_certificate 1_www.domain.com_bundle.crt; ssl_certificate_key 2_www.domain.com.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置 ssl_prefer_server_ciphers on; location / { root html; #站点目录 index index.html index.htm; } }","categories":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/tags/nginx/"}]},{"title":"配置nodejs nginx的反向代理","slug":"配置nodejs-nginx的反向代理","date":"2017-09-25T10:49:56.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/09/25/配置nodejs-nginx的反向代理/","link":"","permalink":"https://anyuzhe.github.io/2017/09/25/配置nodejs-nginx的反向代理/","excerpt":"","text":"upstream nodejs { server 127.0.0.1:3000; keepalive 64;} server { listen 80; server_name www.penguu.com penguu.com; access_log /var/log/nginx/test.log; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-Nginx-Proxy true; proxy_set_header Connection “”; proxy_pass http://nodejs; }}","categories":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/tags/nginx/"}]},{"title":"CentOS7 下 安装 使用 supervisor","slug":"centos使用supervisor","date":"2017-09-10T06:39:05.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2017/09/10/centos使用supervisor/","link":"","permalink":"https://anyuzhe.github.io/2017/09/10/centos使用supervisor/","excerpt":"","text":"CentOS7 下 安装 supervisor 【注】 linux环境必须安装 python 1.获取supervisor包：【https://pypi.python.org/pypi/supervisor】 # wget https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gz 2.解压supervisor-3.3.1.tar.gz 并安装 123# tar zxvf supervisor-3.3.1.tar.gz &amp;&amp; cd supervisor-3.3.1 # python setup.py install 【可能报错】：ImportError: No module named setuptools 【解决办法】：没有setuptools的模块，说明python缺少这个模块，那我们只要安装这个模块即可解决此问题 12345678 # wget http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c11.tar.gz # tar zxvf setuptools-0.6c11.tar.gz &amp;&amp; cd setuptools-0.6c11 # python setup.py build # python setup.py install 3.创建supervisor的配置文件： 1 # echo_supervisord_conf &gt; /etc/supervisord.conf 在配置末尾修改一下include 和配置文件地址[unix_http_server]file=/tmp/supervisor.sock ;UNIX socket 文件，supervisorctl 会使用;chmod=0700 ;socket文件的mode，默认是0700;chown=nobody:nogroup ;socket文件的owner，格式：uid:gid ;[inet_http_server] ;HTTP服务器，提供web管理界面;port=127.0.0.1:9001 ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性;username=user ;登录管理后台的用户名;password=123 ;登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小logfile_backups=10 ;日志文件保留备份数量默认10，设为0表示不备份loglevel=info ;日志级别，默认info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ;pid 文件nodaemon=false ;是否在前台启动，默认是false，即以 daemon 的方式启动minfds=1024 ;可以打开的文件描述符的最小值，默认 1024minprocs=200 ;可以打开的进程数的最小值，默认 200 [supervisorctl]serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord ; [program:xx]是被管理的进程配置参数，xx是进程的名称[program:xx]command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令autostart=true ; 在supervisord启动的时候也自动启动startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启startretries=3 ; 启动失败自动重试次数，默认是3user=tomcat ; 用哪个用户启动进程，默认是rootpriority=999 ; 进程启动优先级，默认999，值小的优先启动redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.outstopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程 ;包含其它配置文件[include]files = relative/directory/*.ini ;可以指定一个或多个以.ini结束的配置文件 配置文件示例 123456789[program:laravel-worker]process_name=%(program_name)s_%(process_num)02dcommand=php /home/forge/app.com/artisan queue:work sqs --sleep=3 --tries=3autostart=trueautorestart=trueuser=forgenumprocs=8redirect_stderr=truestdout_logfile=/home/forge/app.com/worker.log 4.开启supervisord服务 1 # supervisord -c /etc/supervisord.conf 更新新的配置到supervisord 1 # supervisorctl update 重新启动配置中的所有程序 1 # supervisorctl reload 启动某个进程(program_name=你配置中写的程序名称) 1 # supervisorctl start program_name 查看正在守候的进程 1 # supervisorctl 重启某一进程 (program_name=你配置中写的程序名称) 1 # supervisorctl restart program_name 停止全部进程 1 # supervisorctl stop all 5.查看supervisord进程 参考网址：http://supervisord.org/installing.html 踩过的坑 1、unix:///var/run/supervisor/supervisor.sock no such file 问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错 解决办法：supervisord -c /etc/supervisord.conf 2、command中指定的进程已经起来，但supervisor还不断重启 问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，本人使用的是elasticsearch，command 指定的是$path/bin/elasticsearch -d，踩到的坑 解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个3、启动了多个supervisord服务，导致无法正常关闭服务 问题描述：在运行supervisord -c /etc/supervisord.conf 之前，我直接运行过supervisord -c /etc/supervisord.d/xx.conf ，导致有些进程被多个superviord管理，无法正常关闭进程。 解决办法： 使用 ps -fe | grep supervisord 查看所有启动过的supervisord服务，kill相关的进程。","categories":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/categories/python/"}],"tags":[{"name":"temp","slug":"temp","permalink":"https://anyuzhe.github.io/tags/temp/"}]},{"title":"ros 命令行使用记录","slug":"ros_term_record","date":"2017-08-31T06:16:55.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/08/31/ros_term_record/","link":"","permalink":"https://anyuzhe.github.io/2017/08/31/ros_term_record/","excerpt":"","text":"基础命令roscore 基本命令roscd rosls rospack roslog 创建包catkin_create_pkg [depend1] [depend2] [depend3]一级依赖rospack depends1 所有依赖rospack depends 编译包catkin_make [make_targets] [-DCMAKE_VARIABLES=…]指定路径编译包catkin_make –source my_srccatkin_make install –source my_src # (optionally) 节点列出活跃节点rosnode list运行节点rosrun [package_name] [node_name]运行节点取名字rosrun turtlesim turtlesim_node __name:=my_turtle 使用 rqt_graph 查看topic安装sudo apt-get install ros-kinetic-rqtsudo apt-get install ros-kinetic-rqt-common-plugins rostopic -h 查看话题rosmsg show geometry_msgs/Twist 查看消息数据发布到话题上rostopic pub [topic] [msg_type] [args] $ rostopic pub -1 /turtle1/cmd_vel geometry_msgs/Twist – ‘[2.0, 0.0, 0.0]’ ‘[0.0, 0.0, 1.8]’ROS服务和参数rosservice list 输出可用服务的信息rosservice call 调用带参数的服务rosservice type 输出服务类型rosservice find 依据类型寻找服务find services by service typerosservice uri 输出服务的ROSRPC uri $ rosservice type spawn| rossrv showrosparam使得我们能够存储并操作ROS 参数服务器（Parameter Server）上的数据YAML的表述很自然：1 是整型, 1.0 是浮点型, one是字符串, true是布尔, [1, 2, 3]是整型列表, {a: b, c: d}是字典. rosparam有很多指令可以用来操作参数，如下所示: 使用方法: rosparam set 设置参数rosparam get 获取参数rosparam load 从文件读取参数rosparam dump 向文件中写入参数rosparam delete 删除参数rosparam list 列出参数名 你可能希望存储这些信息以备今后重新读取。这通过rosparam很容易就可以实现:rosparam dump and rosparam load 使用方法: rosparam dump [file_name]rosparam load [file_name] [namespace] 现在我们将所有的参数写入params.yaml文件： $ rosparam dump params.yaml 你甚至可以将yaml文件重载入新的命名空间，比如说copy空间: $ rosparam load params.yaml copy$ rosparam get copy/background_b","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"ros","slug":"ros","permalink":"https://anyuzhe.github.io/tags/ros/"}]},{"title":"股票 技术指标 解释","slug":"share_jjjj","date":"2017-08-30T15:50:45.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/08/30/share_jjjj/","link":"","permalink":"https://anyuzhe.github.io/2017/08/30/share_jjjj/","excerpt":"","text":"1、BOLL指标即布林线指标，其英文全称是“Bolinger Bands”，布林线(BOLL)由约翰 布林先生创造，其利用统计原理，求出股价的标准差及其信赖区间，从而确定股价的波动范围及未来走势，利用波带显示股价的安全高低价位，因而也被称为布林带。.当布林线的上、中、下轨线同时向上运行时，表明股价强势特征非常明显，股价短期内将继续上涨，投资者应坚决持股待涨或逢低买入。当布林线的上、中、下轨线同时向下运行时，表明股价的弱势特征非常明显，股价短期内将继续下跌，投资者应坚决持币观望或逢高卖出。当布林线的上轨线向下运行，而中轨线和下轨线却还在向上运行时，表明股价处于整理态势之中。如果股价是处于长期上升趋势时，则表明股价是上涨途中的强势整理，投资者可以持股观望或逢低短线买入；如果股价是处于长期下跌趋势时，则表明股价是下跌途中的弱势整理，投资者应以持币观望或逢高减仓为主。布林线的上轨线向上运行，而中轨线和下轨线同时向下运行的可能性非常小，这里就不作研判。当布林线的上、中、下轨线几乎同时处于水平方向横向运行时，则要看股价目前的走势处于什么样的情况下来判断。 2、Williams %R(简称W&amp;R或%R，中文名威廉指标） 由Larry williams创造，是一种利用振荡点来反映市场超买超卖现象，预测循环周期内的高点和低点，从而提出有效的信号来分析市场短期行情走势，判断市场(通常指股市，但是其他市场也符合此原理）强弱分界的技术指标。当W&amp;R高于80%，即处于超卖状态，行情即将见底，应当考虑买入。W&amp;R低于20%，即处于超买状态，行情即将见顶，应当考虑卖出。在W&amp;R进入高位后，一般要回头，如果这时股价还继续下跌，这就产生背离，是进货的信号。在W&amp;R进入低位后，一般要反转，如果这时股价还继续上升，这就产生背离，是卖出的信号。W&amp;R连续几次撞顶，局部形成双重或多重顶则是出货的信号。 3、DMI指标可以用作买卖讯号，也可辨别行情是否已经发动。但必须注意，当市场的上升（下跌）趋势非常明显时，利用该指标进行买卖指导效果较好，当市场处于盘整时，该指标会失真。DMI指标共有+DI、—DI、ADX、ADXR四条线。当行情的上升（下跌）趋势相当明显时，当+DI向上交叉—DI，则买进，当+DI向下交叉—DI，则卖出。当ADX数值降低到20以下，且显现横盘时，此时股价处于小幅盘整中，当ADX突破40并明显上升时，股价上升趋势确立。如果ADX在50以上反转向下，此时，不论股价正在上涨或下跌，都预示行情即将反转。当4根线间距收窄时，表明行情处于盘整中，这时该指标会失真。 4、BIAS又称为乖离率，是反映股价在波动过程中与移动平均线偏离程度的技术指标。它的理论基础是：不论股价在移动平均线之上或之下，只要偏离距离过远，就会向移动平均线趋近，据此计算股价偏离移动平均线百分比的大小来判断买卖时机。当股价在移动平均线之上时，称为正乖离率，反之称为负乖离率；当股价与移动平均线重合，乖离率为零。在股价的升降过程中，乖离率反复在零点两侧变化，数值的大小对未来股价的走势分析具有一定的预测功能。正乖离率超过一定数值时，显示短期内多头获利较大，获利回吐的可能性也大，呈卖出信号；负乖离率超过一定数值时，说明空头回补的可能性较大，呈买入信号。 5、没有MIKT这个指标。 6、成交量比率（Volume Ratio 简称VR）），是一项通过分析股价上升日成交额（或成交量，下同）与股价下降日成交额比值，从而掌握市场买卖气势的中期技术指标。主要用于个股分析，其理论基础是“量价同步”及“量须先予价”，以成交量的变化确认低价和高价，从而确定买卖时法。下面是VR值所在区域的相对应使用方法。A、低价区域：7040——为可买进区域B、安全区域：15080——正常分布区域C、获利区域：450~160——应考虑获利了结D、警戒区域：450以上——股价已过高 ，赶快卖出 7、OBV的英文全称是：On balance volume,中英名称可翻译为：平衡交易量，是由美国的投资分析家Joe Granville所创。该指标通过统计成交量变动的趋势来推测股价趋势。OBV以“N”字型为波动单位，并且由许许多多“N”型波构成了OBV的曲线图，对一浪高于一浪的“N”型波，称其为“上升潮”，至于上升潮中的下跌回落则称为“跌潮”。OBV构成的基本原理，是根据潮涨潮落的原理。事物向前发展总是有曲折的，不会一帆风顺，正如海浪在向前推进时，中途还有潮落的现象。每次向前的浪潮如果总比向后的浪潮大，则整个趋势还是向前的。OBV能量潮使用方法：当股价上升而OBV线下降，表示买盘无力，股价可能会回跌。股价下降时而OBV线上升，表示买盘旺盛，逢低接手强股，股价可能会止跌回升。OBV线缓慢上升，表示买气逐渐加强，为买进信号。OBV线急速上升时，表示力量将用尽为卖出信号。OBV线对双重顶第二个高峰的确定有较为标准的显示，当股价自双重顶第一个高峰下跌又再次回升时，如果OBV线能够随股价趋势同步上升且价量配合，则可持续多头市场并出现更高峰。相反，当股价再次回升时OBV线未能同步配合，却见下降，则可能形成第二个顶峰，完成双重顶的形态，导致股价反转下跌。OBV线从正的累积数转为负数时，为下跌趋势，应该卖出持有股票。反之，OBV线从负的累积数转为正数时，应该买进股票。OBV线最大的用处，在于观察股市盘局整理后，何时会脱离盘局以及突破后的未来走势，OBV线变动方向是重要参考指数。 8、情绪指标（ARBR）也称为人气意愿指标，其英文缩写亦可表示为BRAR。由人气指标(AR)和意愿指标(BR)两个指标构成。AR指标和BR指标都是以分析历史股价为手段的技术指标。一般情况下，AR指标可以单独使用，BR指标则需与AR指标并用，才能发挥效用。该指标虽不适合捕捉到大底部，但是灵活运用该指标，却能够抓住局部底部，特别适合做反弹。BR＜AR，且BR＜100，可考虑逢低买进。BR＜AR，而AR＜50时，是买进信号；BR&gt;AR，再转为BR&lt;AR时，也可买进。AR和BR同时急速上升，意味着股价已近顶部，持股者应逢高卖出。BR急速上升，而AR处在盘整或小跌时，应逢高卖出。BR从高峰回跌，跌幅达1至2倍时，若AR无警戒讯号出现，应逢低买进。 9、抛物线指标（SAR）也称为停损点转向指标，这种指标与移动平均线的原理颇为相似，属于价格与时间并重的分析工具。由于组成SAR的点以弧形的方式移动，故称“抛物转向”。SAR指标的一般研判标准包括以下四方面：当股票股价从SAR曲线下方开始向上突破SAR曲线时，为买入信号，预示着股价一轮上升行情可能展开，投资者应迅速及时地买进股票。当股票股价向上突破SAR曲线后继续向上运动而SAR曲线也同时向上运动时，表明股价的上涨趋势已经形成，SAR曲线对股价构成强劲的支撑，投资者应坚决持股待涨或逢低加码买进股票。当股票股价从SAR曲线上方开始向下突破SAR曲线时，为卖出信号，预示着股价一轮下跌行情可能展开，投资者应迅速及时地卖出股票。当股票股价向下突破SAR曲线后继续向下运动而SAR曲线也同时向下运动，表明股价的下跌趋势已经形成，SAR曲线对股价构成巨大的压力，投资者应坚决持币观望或逢高减磅。 10、振动升降指标(ASI)，由威尔斯·王尔德（Welles Wilder）所创。ASI指标以开盘、最高、最低、收盘价与前一交易日的各种价格相比较作为计算因子，研判市场的方向性。应用方法：ASI指标大部分时机都是和股价走势同步的，投资者仅能从众多股票中寻找少数产生领先突破的个股。若ASI指标领先股价，提早突破前次ASI高点或低点，则次一日之后的股价必然能突破前次高点或低点。股价由上往下，欲穿越前一波低点的密集支撑区时，于接近低点处，尚未确定股价是否会跌破支撑之际，如果ASI领先股价，提早一步，跌破相对股价的前一波ASI低点，则次一日之后，股价将随后跌破低点支撑区。投资人可以早一步卖出股票，减少不必要的损失。股价由下往上，欲穿越前一波的高点套牢区时，于接近高点处，尚未确定股价能否顺利穿越之际，如果ASI领先股价，提早一步，通过相对股价的前一波ASI低点，则次一日之后，股价必然能够顺利突破高点套牢区。股民可以把握ASI的领先作用，提前买入股票。股价走势一波比一波高，而ASI却未相对创新高点形成“顶背离”时，应卖出；股价走势一波比一波低，而ASI却未相对创新低点形成“底背离”时，应买进。ASI指标和OBV指标同样维持“N”字型的波动，并且也以突破或跌破“N”字型高低点，为观察ASI指标的主要方法。向上爬升的ASI，一旦向下跌破其前一次显著的N型转折点，一律可视为停损卖出的讯号；向下滑落的ASI，一旦向上突破其前一次的N型转折点，一律可视为果断买进的讯号。","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"share","slug":"share","permalink":"https://anyuzhe.github.io/tags/share/"}]},{"title":"ubuntu ros 安装记录","slug":"ros_install_record","date":"2017-08-29T06:33:11.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/08/29/ros_install_record/","link":"","permalink":"https://anyuzhe.github.io/2017/08/29/ros_install_record/","excerpt":"","text":"安装sudo apt-get updatesudo sh -c ‘echo “deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main” &gt; /etc/apt/sources.list.d/ros-latest.list’sudo apt-key adv –keyserver hkp://ha.pool.sks-keyservers.net:80 –recv-key 0xB01FA116sudo apt-get install ros-kinetic-desktop-full 初始化 rosdepsudo rosdep initrosdep updatesudo rosdep updatesudo rosdep fix-permissionsrosdep update 环境配置echo “source /opt/ros/kinetic/setup.bash” &gt;&gt; ~/.bashrcsource ~/.bashrc sudo apt-get install python-rosinstallsudo apt-get install ros-kinetic-libfreenectsudo apt-get install ros-kinetic-freenect-launch# roslaunch freenect_launch freenect.launch sudo apt-get install libusb-1.0-0-devsudo apt-get install ros-kinetic-openni2-camerasudo apt-get install ros-kinetic-openni2-launchsudo apt-get install ros-kinetic-openni-launchroslaunch openni2_launch openni2.launchroslaunch freenect_launch freenect.launchrosrun rviz rviz mkdir -p ~/catkin_ws/srccd catkin_ws/catkin_makesource devel/setup.bashecho $ROS_PACKAGE_PATHrospack find openni2_launch","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"ros","slug":"ros","permalink":"https://anyuzhe.github.io/tags/ros/"}]},{"title":"理解 IntelliJ IDEA 的项目配置和Web部署","slug":"理解IntelliJ-IDEA的项目配置和Web部署","date":"2017-08-17T11:04:36.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/08/17/理解IntelliJ-IDEA的项目配置和Web部署/","link":"","permalink":"https://anyuzhe.github.io/2017/08/17/理解IntelliJ-IDEA的项目配置和Web部署/","excerpt":"","text":"1、项目配置的理解IDEA 中最重要的各种设置项，就是这个 Project Structre 了，关乎你的项目运行，缺胳膊少腿都不行。最近公司正好也是用之前自己比较熟悉的IDEA而不是Eclipse，为了更深入理解和使用，就找来各种资料再研究一下，这里整理后来个输出。 1.1 Project Project name：定义项目的名称； Project SDK：设置该项目使用的JDK，也可以在此处新添加其他版本的JDK； Project language level：这个和JDK的类似，区别在于，假如你设置了JDK1.8，却只用到1.6的特性，那么这里可以设置语言等级为1.6，这个是限定项目编译检查时最低要求的JDK特性； Project compiler output：项目中的默认编译输出总目录，如图黄色部分，实际上每个模块可以自己设置特殊的输出目录（Modules - (project) - Paths - Use module compile output path），所以这个设置有点鸡肋。 1.2 Modules1.2.1 增删子项目一个项目中可以有多个子项目，每个子项目相当于一个模块。一般我们项目只是单独的一个，IntelliJ IDEA 默认也是单子项目的形式，所以只需要配置一个模块。（此处的两个项目引入仅作示例参考） 1.2.2 子项目配置每个子项目都对应了Sources、Paths、Dependencies 三大配置选项： Sources：显示项目的目录资源，那些是项目部署的时候需要的目录，不同颜色代表不同的类型； Paths：可以指定项目的编译输出目录，即项目类和测试类的编译输出地址（替换掉了Project的默认输出地址） Dependencies：项目的依赖 1.2.3 增删框架（Web部署-1）2.每个子项目之下都可以定义它所使用的框架，这里重点说明一下Web部分的设置。 1.3 Libraries这里可以显示所添加的jar包，同时也可以添加jar包，并且可以把多个jar放在一个组里面，类似于jar包整理。 这里默认将每个jar包做为了一个单独的组（未测试，待定）。 1.4 Facets官方的解释是：When you select a framework (a facet) in the element selector pane, the settings for the framework are shown in the right-hand part of the dialog.（当你在左边选择面板点击某个技术框架，右边将会显示这个框架的一些设置） 说实话，并没有感觉到有什么作用。 1.5 Artifacts（Web部署-2）项目的打包部署设置，这个是项目配置里面比较关键的地方，重点说一下。 先理解下它的含义，来看看官方定义的artifacts：An artifact is an assembly of your project assets that you put together to test, deploy or distribute your software solution or its part. Examples are a collection of compiled Java classes or a Java application packaged in a Java archive, a Web application as a directory structure or a Web application archive, etc. 即编译后的Java类，Web资源等的整合，用以测试、部署等工作。再白话一点，就是说某个module要如何打包，例如war exploded、war、jar、ear等等这种打包形式。某个module有了 Artifacts 就可以部署到应用服务器中了。（jar：Java ARchive，通常用于聚合大量的Java类文件、相关的元数据和资源（文本、图片等）文件到一个文件，以便分发Java平台应用软件或库；war：Web application ARchive，一种JAR文件，其中包含用来分发的JSP、Java Servlet、Java类、XML文件、标签库、静态网页（HTML和相关文件），以及构成Web应用程序的其他资源；exploded：在这里你可以理解为展开，不压缩的意思。也就是war、jar等产出物没压缩前的目录结构。建议在开发的时候使用这种模式，便于修改了文件的效果立刻显现出来。）默认情况下，IDEA的 Modules 和 Artifacts 的 output目录已经设置好了，不需要更改，打成war包的时候会自动在 WEB-INF目录下生成classes，然后把编译后的文件放进去。 你可能对这里的输出目录不太理解，之前不是配置过了文件编译的输出目录了吗？为什么这里还有一个整合这些资源的目录呢？它又做了哪些事呢？ 其实，实际上，当你点击运行tomcat时，默认就开始做以下事情： 编译，IDEA在保存/自动保存后不会做编译，不像Eclipse的保存即编译，因此在运行server前会做一次编译。编译后class文件存放在指定的项目编译输出目录下（见1.2.2）； 根据artifact中的设定对目录结构进行创建； 拷贝web资源的根目录下的所有文件到artifact的目录下（见1.2.3）； 拷贝编译输出目录下的classes目录到artifact下的WEB-INF下（见1.2.2）； 拷贝lib目录下所需的jar包到artifact下的WEB_INF下； 运行server，运行成功后，如有需要，会自动打开浏览器访问指定url。在这里还要注意的是，配置完成的artifact，需要在tomcat中进行添加：2、参考链接 IntelliJ IDEA 项目相关的几个重要概念介绍 Dependencies Tab Facet Page Working with Artifacts Intellij IDEA 14.x 中的Facets和Artifacts的区别 IntelliJ使用指南—— 深入理解IntelliJ的Web部署逻辑 IntelliJ IDEA WEB项目的部署配置","categories":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/tags/java/"}]},{"title":"nginx配置limit_conn_zone来限制并发连接数以及下载带宽","slug":"nginx配置limit_conn_zone来限制并发连接数以及下载带宽","date":"2017-07-30T17:54:35.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2017/07/31/nginx配置limit_conn_zone来限制并发连接数以及下载带宽/","link":"","permalink":"https://anyuzhe.github.io/2017/07/31/nginx配置limit_conn_zone来限制并发连接数以及下载带宽/","excerpt":"","text":"配置方法如下： 1、在nginx.conf里的http{}里加上如下代码： #ip limit limit_conn_zone $binary_remote_addr zone=perip:10m; limit_conn_zone $server_name zone=perserver:10m;复制代码2、在需要限制并发数和下载带宽的网站配置server{}里加上如下代码： limit_conn perip 2; limit_conn perserver 20; limit_rate 100k;复制代码补充说明下参数： $binary_remote_addr是限制同一客户端ip地址； $server_name是限制同一server最大并发数； limit_conn为限制并发连接数； limit_rate为限制下载速度；转另一篇文章：http://hxl2009.blog.51cto.com/779549/1324473 注意： nginx 1.1.8 之后的版本的语法改为limit_conn_zone $binary_remote_addr zone=NAME:10m; NAME 就是 zone 的名字详情请看这里 http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html 限制连接数: 要限制连接，必须先有一个容器对连接进行计数，在http段加入如下代码： “zone=” 给它一个名字，可以随便叫，这个名字要跟下面的 limit_conn 一致 $binary_remote_addr = 用二进制来储存客户端的地址，1m 可以储存 32000 个并发会话 … 省掉 N 字 http { limit_conn_zone $binary_remote_addr zone=addr:10m; 接下来需要对server不同的位置（location段）进行限速，比如限制每个IP并发连接数为1，则 server { listen 80; server_name 192.168.11.128; index index.html index.htm index.PHP; limit_conn addr 1; #是限制每个IP只能发起1个连接 （addr 要跟 limit_conn_zone 的变量对应） limit_rate 100k; #限速为 100KB/秒 root html; 注意事项： limit_rate 100k; //是对每个连接限速100k。这里是对连接限速，而不是对IP限速！如果一个IP允许两个并发连接，那么这个IP就是限速limit_rate * 2","categories":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/tags/nginx/"}]},{"title":"java基础 知识点","slug":"java基础-知识点","date":"2017-07-23T17:08:03.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/07/24/java基础-知识点/","link":"","permalink":"https://anyuzhe.github.io/2017/07/24/java基础-知识点/","excerpt":"","text":"####void无返回值的 这里是方法的副作用和返回值类型 一个方法的执行，如果在返回一个值之外还导致某些外部“状态”发生变化，则称该方法产生了副作用。这里所谓“状态”发生变化，可以是实例域或静态变量被修改 1.没有返回值的方法必然有副作用，除非它的方法体是空的或者方法没有意义。所以，没有返回值的方法、有返回值但有副作用的方法称为过程 2.有返回值而且没有副作用的方法称为函数(function) 由于java的主函数是栈中最底层的函数，所以并不存在能够接收的值，所以使用void，无返回的 ####main方法名（注意是main，很多初学者都会写成mian，这是不一样的） main是java主方法的方法名，是不能被改变的，就算错了一个字也是不可以运行的。 由于java中有关键字（保留字）存在的机制，所以main也类似与一个关键字（但不是），jvm运行时，只会找符合要求的main单词，所以将main改变后，jvm将找不到主入口，方法将不能执行。当然，main也可以作为方法名存在。也可以作为变量名存在。 在一个类中可以存在多个main方法，这是方法的重载。在名字相同的同时，必须有不同的参数。不允许参数完全相同而只是返回值不同的情况出现。无法进行编译，程序在eclips中显示错误 servlet 教程麦子学院 SPRING MVC 基础配置 ssm 基础配置慕课java 实战看到的教材IntelliJ IDEA上创建Maven Spring MVC项目 IDEA搭建SpringMVC并用maven配置的小例子 ssm个人博客项目实战01】SSM环境搭建","categories":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://anyuzhe.github.io/tags/java/"}]},{"title":"炒股学习的记录","slug":"share_way_record","date":"2017-07-06T13:52:56.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/07/06/share_way_record/","link":"","permalink":"https://anyuzhe.github.io/2017/07/06/share_way_record/","excerpt":"","text":"股票大作手回忆录 加仓11.3 1000 11.4 2000 11.5 3000 上升 下降11.5 买入 4000 如果没有上涨 需要卖出 出售试探或者加仓 跟着市场走，确定市场大势，人不可能击败市场 大钱必然，也智能来自大规模行情 他的目标不是为了按照一个比较有利的利率水平获取固定的资金收益，而是通过价格的上升或下降而博取收益 需要判定的关键因素是从交易的那一刻向前展望阻力最小的行情路线，耐心等待，市场明确界定自身阻力最小的行情路线 永远不因为股票价格太高而不能买入，不因为价格太低而不能卖出，实质上，这个价格与我确定阻力最小的路线毫无关系 当价格谈不上任何明确方向而是只在狭窄范围内横向延伸时，企图预料市场下一步大动作时向上或向下是毫无道理的 应该做的是确定价格上下的极限距离，在哪一个方向上突破了否则绝不沾手 预期市场上涨而买进股票的时候支付高位的价格，卖出则必须是低价卖出 随着市场上升，逐步加仓，而没有形成利润，绝不可以增加持仓","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"share","slug":"share","permalink":"https://anyuzhe.github.io/tags/share/"}]},{"title":"Symfony 教学文章梳理","slug":"symfony_learn","date":"2017-07-04T14:44:17.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/07/04/symfony_learn/","link":"","permalink":"https://anyuzhe.github.io/2017/07/04/symfony_learn/","excerpt":"","text":"symfony中文站 symfony中国 sf上的symfony板块","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"},{"name":"symfony","slug":"symfony","permalink":"https://anyuzhe.github.io/tags/symfony/"}]},{"title":"pyqt 教程文章纪录","slug":"pyqt教程文章纪录","date":"2017-06-16T18:58:21.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/06/17/pyqt教程文章纪录/","link":"","permalink":"https://anyuzhe.github.io/2017/06/17/pyqt教程文章纪录/","excerpt":"","text":"PyQt5+Eric6+Anaconda+Pycharm 开发Qt应用环境搭建 麦子学院视频教程 鱼c论坛 Anaconda使用总结 【Python专题】 使用pycharm+pyqt5 调取界面程序 pycharm集成pyqt设置步骤 PyQt5简单例程及在PyCharm中设置PyQt5 知乎pyqt5 不使用集成环境的pyqt设置macOS(Xcode)+Python2.7配置PyQt5","categories":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/tags/python/"}]},{"title":"基于 React Native 的移动平台研发实践-转","slug":"基于-React-Native-的移动平台研发实践","date":"2017-05-11T09:41:38.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/05/11/基于-React-Native-的移动平台研发实践/","link":"","permalink":"https://anyuzhe.github.io/2017/05/11/基于-React-Native-的移动平台研发实践/","excerpt":"","text":"下面，有请@小玻玻@普元云计算 为大家直播课程，14:30郝总准时开讲，本节课后安排郝总答疑，祝大家交流愉快。 大家下午好，我是小玻玻，我现在在上海，现在上海天气达到了30度，希望我们今天的微课保持同样的热度。 课程简介：从 2016 年以来，Gartner 提出了一个新的移动前端技术的分类——Javascript Frameworks for Native Mobile，无论是 React Native、还是 WeeX、以及普元移动平台都属于这类技术。本次分享是普元移动产品部在基于 React Native 进行移动平台研发过程的实践，希望能够抛砖引玉。分享将会围绕以下几个方面进行阐述： 课程大纲：1、React Native 成为趋势2、React Native 实践的一些问题（1）React Native 的学习成本与可替代性（2）单 Bundle 与多 Bundle 的思考（3）如何能够更高效的调试（首屏 VS 当前屏）（4） 热更新与按需更新3、基于 RN，我们的实践分享（1）Bundle 的拆解的思考（2）基于 RN 的扩展（Require、编译等）（3）当前屏调试（4）按需更新的实现 嘉宾介绍：郝振明十多年 IT 从业经验，一直专注于企业信息化的工作，近五年间一直从事企业移动信息化、移动互联网化的咨询、产品工作，曾主持参与了 Primeton Mobile 产品研发、联通集团、广东农信、诺亚财富、中信重工、索菲亚等公司的移动信息化工作。近两年来，致力于基于 React Native 工程化能力的提升、降低实施难度，以及智能化移动平台的产品研发，在移动开发智能化的路上不断进行探索。 5月11日郝振明《基于 React Native 的移动平台研发实践》签到链接请移步→http://t.cn/RaJYok9，大家可前往注册EAII会员享受课前PPT发送，不定期抽奖等一系列权益 大家好，我是普元移动平台总负责人郝振明，很荣幸今天有机会以微课堂的方式与大家在微信群里见面，分享一下我们基于React Native的移动平台研发的一些实践。期望抛砖引玉，也欢迎大家多多指教。 今天的分享我会主要围绕着三个方向展开： 1、 React Native 已经成为了移动前端技术的趋势。2、 基于React Native 进行移动平台研发过程中的一些思考。3、 基于React Native 进行移动平台研发过程中的一些实践。 1、React Native已经成为了移动前端技术的趋势 从2014年年底，Facebook计划开源React Native 的时候，我就已经开始关注TA了，关注的主要原因是，我们在2012年的时候，将我们的移动平台前端开发技术确定为“DSL-&gt;Javascript-&gt;Native Mobile”这个技术流派。要知道在那个时代，绝大多数的友商要么选择Hybrid，要么选择HTML5作为移动平台的跨平台前端解决方案。 然而，这两种方案最终的UI渲染，本质上都需要依赖Webkit，通俗点说就是UI最终是通过浏览器内核渲染。我们当时在技术选型的时候实在无法容忍Webkit在Andriod上的体验，而选择了驱动原生（注：这个名字是我起的，也是为了区别于传统的Hybrid技术）的方式。 当时的这个技术抉择，在当时是冒着巨大的风险的，现在看来，我们是非常幸运的。 后来Facebook 推出React Native 后，阿里系也推出了自己的Weex，甚至Gartner针对这类技术在2016年的报告（IT Market Clock for Mobile App Development, 2016 ）中首次出现并并为这个技术流派起了一个名字——Javascript Frameworks for Native Mobile。 Garnter将这个技术流派当如了“Advantag”中，可见Gartner对这个技术流派的认可。 Javascript Frameworks for Native Mobile这类技术的几个特点： 1、 开发期基本采用类Web语言，比如React的语法2、 运行期并不是采用Webkit做渲染，而是采用Native的渲染方式。3、 与Native 进行交互的通道是采用Javascript的方式。 当然，因其技术的先进性让各大互联网公司纷纷进行实践上的尝试，取得了不错的效果，包括天猫、腾讯QQ、手机百度、美团点评、携程等等。React Native 也建立了很好的生态，大家对案例如果有兴趣可以关注一下https://facebook.github.io/react-native/showcase.html 。 考虑到群里的很多朋友对React Native 有了很深刻的理解，我这里将跳过React Native原理上的阐述，如果大家有兴趣可以分享之后加我微信一起讨论。 下面，我来讲 第二部分：基于React Native 进行移动平台研发过程中的一些思考 尽管React Native 在移动前端存在着无可比拟的优势，但每一家在工程化的过程中还是存在各自不同的思考。而作为移动平台，不是简单的解决单一的一个App的问题。 移动平台是支撑企业全面移动信息化的平台，需要解决企业面向不同场景下的各种诉求。针对移动App的使用者的场景不同，存在面向人和面向组织两种不尽相对的要求： 面向人：每个人对应的App功能是基本相同的。人与人是平等的，就如今天在线的各位和我一样，在支付宝里看到的功能是相同的。这种情况多出现在面向最终消费者的时候。 面向组织：是指功能因其所属的组织和职级决定了其所见和所能用的功能。当事人所处的组织机构发生了变化，功能也随之产生变化。 针对面向组织，需要举个例子来说明一下：假如我本人之前是一名普通的manager，其实对于产品线的经营报告并无权阅读（图一）；当我被Promote 为产品线总经理的时候，我的App里就应该有“智能报表”的微应用（图二）；当我调岗到别的团队（比如从事行政工作），我就不应该再具有“智能报表”的相关功能（图三），如下图所示： 随着岗位和职级的变化，功能从图一到图二再到图三，我还是我，而我App内的功能却发生了变化，这在企业中是非常常见的诉求。 实现上述的功能，从技术方案角度看，有多种方式，但是怎么更合理呢？我们可以思考一下。 首先，“智能报表”功能是否可以将UI已经打入App中，通过权限控制对应的前端“智能报表”是否显示？回答是不可以。主要原因有三： 第一、类似这种功能在企业中非常多，如果要将UI全都打入到App中，这需要所有功能的全集，没有三四百M下不来。而用户实际上只有权限使用几分之一甚至是十分之一的功能，却要每次为此多更新两三百M，这是不合理的。 第二、如果智能报表这个功能在用户安装ipa或者apk的时候，尚未开发完成，而是后续才迭代上线的，那么这个用户就无法及时使用到这个功能。 第三、如果失去了相关的功能权限，需要的是相关的功能清除，甚至包括其相关的数据，而不是简单的隐藏，这既不安全又不合理。 这就意味着，移动平台必须能够动态的方式更新应用内功能，而且必须能够结合权限提供按需的热更新能力。 其次，在企业中不得不面对的是多供应商的问题，智能报表功能跟其他功能（比如：审批）是一个开发团队开发的吗？ 显然，在企业中完全有可能是不同的供应商进行的开发。不同供应商之间，不可能做到代码级的共享的，拿到所有移动项目的代码再进行打包，这是一件非常难以推动的事情。 移动平台必须保证对于多团队、跨地域的方式也能支持并行研发。这就意味着必须提供开发期的隔离。 移动平台需要支撑上述的业务场景，显然直接使用React Native 是难以满足要求的，这就引发了我们对于React Native实践的一些思考。 思考一：React Native 的学习成本和可替换性 作为移动平台，不得不考虑的是学习成本，在企业的供应商中是否能够对React Native的技术储备达到相关的要求，如何能够屏蔽对于技术实现的细节。 众所周知，React Native 发布版本非常的频繁，一个周之前已经发到0.44，对于大规模使用时如何屏蔽版本的频繁升级导致的业务代码的重构，方便进行版本的可替换性。 如果能够将React Native实现换成其他实现（比如Weex），而上层业务代码能否不需要调整，真正做到实现的可替换性。 基于这一点的思考，移动平台采用了基于传统Web语法的DSL，作为开发期语言，降低了RN的学习成本；同时DSL层可以隔离业务代码与平台实现相关性，为后续RN版本更新等提供了良好的隔离，大致的示意图如下： 这里需要说明的一点是，我们并没有真正考虑基于Weex作为移动平台的一种实现，而是从技术架构上成为一种可能性。 思考二：React Native 的单bundle VS 多bundle 在谈论React Native的单Bundle与多Bundle的问题之前，首先，我们先回头看一下React Native 默认的Bundle 机制。 在基于RN编写App时，无论开发期创建多少个文件，RN都会将这些文件一并打到一个bundle里去，简单说默认的RN就是一种单bundle的方式，其打包bundle的大概过程如下： 因React Native 默认采用的是单Bundle的模式，所以，其更新机制也就仅仅能够以替换这个Bundle的方式进行，虽然有一些通过diff的方式提供增量更新的方式，但这种方案仍然无法满足上面例子中的“智能报表”的按需获取的能力。 另外，在进行编译打包的时候，需要获取所有项目的源代码，这对于多供应商的情况下也不适用。 所以需要解决的两个问题是： 1、在打包Bundle时，必须提供以多Bundle的方式进行。2、在开发期，必须解决多微应用每个能够独立以Project的方式存在。 思考三：React Native 的调试的首屏进入VS 当前屏刷新 对于开发工程师，很重要的工作就是调试，以RN默认的单Bundle模式，势必会带来另外一个挑战，就是当资源发生任何变化时，必须重复上述的打包Bundle的过程并进行加载，看到的UI界面永远是第一屏。 实际上，我们期望的绝大多数场景是看到当前修改的资源所在的屏的UI效果。从这个维度看，我们必须能够将Bundle控制在一个资源的粒度，并确保当前bundle的动态热更。 另外，虽然React Native 默认不承诺跨平台，但跨平台（即一套代码同时支持iOS、Andriod）是移动平台的必备特性了。如何能够支持多屏同时调试，也将是一个必须考虑的问题。 思考四：React Native 的热更新VS 按需更新 说到热更新，这里不得不提的是几个月前，一堆的App被苹果拒掉的事情，这个事情曾一度让React Native 等Javascript Frameworks for Native Mobile 技术流派背黑锅。 其实这件本质上还是因为某些热更方案调用了私有的API而引起的，后来导致的局面时一堆三方的SDK都受到牵连，最终导致了使用这些SDK的App被拒。插一句，我个人觉着第三方的SDK在没有让使用它们的App知晓的情况下就进行热更新，就是耍流氓，谁又能保证更新后的SDK不做点什么呢。 回到热更本身，我认为，基于React Native 进行热更应该是一个必须的特性，而实际上我们需要提高要求，提供按需更新的能力。 最后一个部分：基于React Native 进行移动平台研发过程中的一些实践 基于上面的一些思考，我们基于React Native进行了一些实践，这里挑出几点给各位做个简单分享。 实践一：引入DSL层 首先，我们引入了DSL层，这里的语法采用了传统Web工程师熟知的HTML、CSS、Javascript，而使用移动平台的工程师无须对React进行过多的深入。在HTML的标签定义中，从语义上尽量能够对开发人员亲切，从习惯上尽量保留原有开发人员的一些习惯，比如对state的封装以getter、setter的方式提供能力，而这些标签需要一一以React Component的方式进行了实现。我们以Label为例（后续出现的代码均为示例代码片段）： DSL语言会在开发期编译成JSX，然后再编译成可被React Native 运行的javascript（涉及到拆分Bundle和编译，这里暂不展开）。 DSL编译成JSX，主要的工作原理大致如下： 1、 HTML 标签的处理，主要是与RN的render进行关联2、 CSS 的处理，主要是与RN的StyleSheet进行映射3、 Javascript的处理，主要是嵌入到JSX中。 上面的代码示例左侧为基于DSL语言编写的代码，右侧是生成JSX后的代码。 实际上，在工程化过程中，并不是像上面的示例代码那么容易做好，无论标签的定义，还是从DSL转换成JSX都是一个巨大的工程，且会遇到很多的问题。 实践二：拆分Bundle 在拆分Bundle上，我们遵守两个原则： 1、将系统库作为一个bundle文件，独立存在。2、将每个的Module作为一个独立bundle文件。 这种拆分原则将bundle拆分成小粒度的针对Module级别的bundle，这带来的好处是，可以方便的跟DSL中HTML文件进行一一映射，其加载单元的粒度可以理解为Page级别，而非整个App。 我们以require 为例，下图为默认的加载方式，如果没有对应的Module Factory，就会以异常结束，如下图： 扩展后，当判断没有对应的Module Factory的情况下，并不是以异常退出，而是增加了加载对应的Module级别的bundle，如下图所示； 当然，这就必须需要移动平台自行实现RTC_PM_JSCExcutor用于加载Module级别的Bundle。这一部分代码需要采用原生的Object-C或者Andriod Java实现，下面以iOS的示例代码 实践三：引入微应用 在将每个Module打成一个Bundle后，会让项目内资源的关系不易管理，这时我们引入了微应用的概念，用于完善应用内逻辑关系。 1、将原有的一个App对应一个Bundle的模式，改成一个App对应多个MicroApp，一个MicroApp对应多个Bundle模式。 2、将原有的一个Bundle对应多个Module的模式，裁剪成一个Bundle对应一个Module的模式 实践四：多屏调试 多屏调试与当前屏刷新，在移动平台IDE端的产品的定义中还是占有很重要的地位，因其直接影响了开发期的效率。 针对React Native 默认的编译核心框架，我们简单的可以总结为四件事情： 1、 node-haste：主要是监听Module变化 ，把变化的Module从Module缓存中移除。2、 ModuleCache：Module编译缓存，把编译好的Module缓存起来，Module没有发生变化的情况下，直接使用缓存组装成bundle3、 Resolver：实现全局系统级库，语法级兼容实现，包括:ES5,ES6实现 兼容实现的引入 。实现Module factory的包装4、 JSTransformer：调用Babel编译JSX文件到JS。 其中1和2有很大原因是因为单bundle导致，当每个HTML文件对应一个Module，每个Module 对应一个bundle后，移动平台需要的就是监听HTML等文件的资源变化即可。如下图： 而这里的编译引擎基本上做的事情是：1、 DSL-&gt;JSX2、 JSX-&gt;js 其中后者主要的工作如下所示： 而为了能够更好的调试，需要对相关两种更新机制： 1、 批量更新a) 包括初次批量更新部署，下载所有文件b) 使用过程中检查文件更新部署，判断需要更新的文件列表 2、 单页更新单页更新是确保其可以当前页保存，当前页刷新调试的主要机制 通过上述的方式，结合移动平台的IDE，可以提供 1、同时支持多手机终端的多屏调试（可以同时iOS和Andriod）2、提供了当前屏动态刷新动态调试 实践五：按需热更 当上述的实践完成后，按需更新就成了一个相对较容易做到的事情。所以移动平台提供了两级打包编译机制，在无需调整代码的情况下，可以选择以微应用的方式出现其他的App内，还是以独立的ipa／apk的方式存在以移动设备中。其基本原理如下图所示： 小结： 基于React Native进行移动平台研发是一个系统性的工程，上述的工作仅仅是其中的一小部分，期间的坑还有很多，今天的分享也仅是从大粒度的方面进行了分享，欢迎加我微信或者关注我们的公众号（EAWorld），一起探讨。 实字群提问：rn现在版本号还很低。而且根据某个版本做出来的东西升级rn版本后总是出错。对于这种情况，您能不能给些建议？ 讲师回答：这个确实是一个必须要考虑的事情。在我们的考虑中，是使用DSL隔离业务代码和RN框架的强依赖关系，简单点说，业务的移动端代码，是基于DSL层编程。这一点在实践一里面提了一下。 实字群提问：请问能不能详细说说dsl的实践情况？有没有什么参考资料？对于小团队加上dsl层是不是非常困难？ 讲师回答：DSL的实践，对于小团队确实有一定的门槛，DSL可以参考移动平台的API手册。其实最近的微信小程序，也可以理解为一种DSL语言，你也可以参考。另外，RN的升级确是比较棘手，建议不要每个小的版本都进行升级。 提问：两级编译最终生成跨平台包的过程中，需要对中间结果手工调整吗？ 提问：rn不像android或iOS平台有自己完整的系统，他很多功能的实现都依赖于第三方库或工具。这就造成了选择第三方工具时非常困难。有时候我好不容易决定用某个库，但是发现这个库的一些依赖不支持我现用的rn版本。对于选择第三方工具和库您能不能给些意见？ 讲师回答：对于第三方的依赖，我们是将RN的体系拨开了看，比如在实践四中提到的RN编译的四件事情，第一个node-haste，我们就没有依赖，而是通过IDE的资源监听来替换，所以就无须依赖相关的三方工具了 鹤字群提问：微应用可以做到按权限显示吗？ 讲师回答：对的，是按照权限显示的，由于时间原因，今天的第五点没有展开。在我们的产品中，更新服务器是结合权限认证的。App的更新策略是与更新服务器进行确认的 享字群提问：怎么可以多屏调试 讲师回答：多屏调试这个章节中提到了IDE，在开始调试的之前，IDE和手机端（可以理解为一个调试的APP）已经预先建立的通讯，这个通讯是支持1（IDE）对多（手机终端）。当IDE发现有资源变更的情况下，产生changlist，IDE的网络服务会跟调试客户端产品通讯。调试客户端按需更新（参加分享中提到的两种更新机制）js文件，每一个js都是独立的Bundle，每一个调试客户端会单独重新load这个文件。这需要IDE和多调试客户端配合起来工作的","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"temp","slug":"temp","permalink":"https://anyuzhe.github.io/tags/temp/"}]},{"title":"php源码阅读 文章梳理","slug":"php_source_code","date":"2017-05-08T14:18:29.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/05/08/php_source_code/","link":"","permalink":"https://anyuzhe.github.io/2017/05/08/php_source_code/","excerpt":"","text":"PHP-Zend引擎剖析之词法分析","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"python appium 可能需要用到的 代码片段","slug":"python_appium_code_part","date":"2017-04-30T16:13:49.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/05/01/python_appium_code_part/","link":"","permalink":"https://anyuzhe.github.io/2017/05/01/python_appium_code_part/","excerpt":"","text":"2.日志法a、启动待测apkb、开启日志输出：adb logcat&gt;D:/log.txtc、关闭日志输出：ctrl+cd、查看日志直接搜索 ：Displayed找寻：Displayed com.mm.android.hsy/.ui.LoginActivity: +3s859msappPackage = com.mm.android.hsyappActivity = .ui.LoginActivity #JDKexport JAVA_HOME=/Library/Java/Homeexport JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:/usr/local/Cellar/ant/1.10.1/libexec/lib/ant-launcher.jar;export PATH=$PATH:$JAVA_HOME/bin #ANDROIDexport ANDROID_HOME=/Users/zhenglong/Library/Android/sdkexport PATH=$ANDROID_HOME/platform-tools:$PATHexport PATH=$ANDROID_HOME/tools:$PATH export PATH=”/Users/zhenglong/anaconda/bin:$PATH”export ANT_HOME=/usr/local/Cellar/ant/1.10.1 python book 使用 ThreadPoolExecutor 相对于手动实现的一个好处在于它使得 任务提交者更方便的从被调用函数中获取返回值。例如，你可能会像下面这样写： 1234567891011121314151617from concurrent.futures import ThreadPoolExecutorimport urllib.requestdef fetch_url(url): u = urllib.request.urlopen(url) data = u.read() return datapool = ThreadPoolExecutor(10)# Submit work to the poola = pool.submit(fetch_url, &apos;http://www.python.org&apos;)b = pool.submit(fetch_url, &apos;http://www.pypy.org&apos;)# Get the results backx = a.result()y = b.result() 例子中返回的handle对象会帮你处理所有的阻塞与协作，然后从工作线程中返回数据给你。 特别的，a.result() 操作会阻塞进程直到对应的函数执行完成并返回一个结果 多进程代码 示例 12345678910def find_all_robots(logdir): &apos;&apos;&apos; Find all hosts across and entire sequence of files &apos;&apos;&apos; files = glob.glob(logdir+&apos;/*.log.gz&apos;) all_robots = set() with futures.ProcessPoolExecutor() as pool: for robots in pool.map(find_robots, files): all_robots.update(robots) return all_robots https://ftp.dlitz.net/pub/dlitz/crypto/pycrypto/pycrypto-2.6.1.tar.gz","categories":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/tags/python/"}]},{"title":"方法容器-流程控制模式 的控制器编写模式（发布文）","slug":"方法容器-流程控制模式-的控制器编写模式(发布文)","date":"2017-04-29T11:44:26.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/04/29/方法容器-流程控制模式-的控制器编写模式(发布文)/","link":"","permalink":"https://anyuzhe.github.io/2017/04/29/方法容器-流程控制模式-的控制器编写模式(发布文)/","excerpt":"","text":"mvc模式里的 c 也就是控制器，在每次编写代码的过程中，其中有一大部分高度复用的如果把这部分代码解耦出来，并且保证其原子性，成为可以高度复用的方法，可以带来极大的好处可以减少重复的代码，在减少代码的同时也会减少bug代码的产生，并且容易修改这是Repository模式的作用 那控制器里的代码 有多少可以封装到respository类里呢？我觉得是90%以上(除了调用代码)所以我在这里想提出一种模式也就是标题 方法容器-流程控制模式 简单来说就是有一个方法容器，可以依次调用你定义的方法(也就是respository里的方法)，最后返回参数 它的好处是，像laravel调用控制器的方法一样 自动传入参数，你只需要在方法中申明需要的参数方法容器去调用的时候，会自动传入参数，这些参数就是方法容器类里的参数这个属性里的，或者是laravel容器里定义的对象(这个就和控制器里的一样) 变量是前者，而申明的是类就是后者 抄袭了laravel里的代码 可以对单个方法做缓存 强迫自己写原子性的方法，提高代码的复用 让控制器里的代码非常直观 而在写控制器方法的时候，其实写的是调用流程，我们一起来看一下到底是咋回事 这是git仓库(看名字就知道 依赖于laravel)laravel-function-flow 首先用composer加载包 composer require anyuzhe/laravel-function-flow 在配置文件config/app.php的服务容器数组中加入 \\Anyuzhe\\LaravelFunctionFlow\\FunctionFlowServiceProvider::class, 在门面数组中加入 ‘Flow’ =&gt; \\Anyuzhe\\LaravelFunctionFlow\\FlowFacade::class, 执行命令 生成配置文件 php artisan funcFlow:publish 会在config文件夹中生成function-flow.php文件 可在里面配置仓库类 类似如下 123456789101112return array(//&apos;Base&apos;=&gt;BaseController::class 类似这样的key value定义类 名称和位置 无任何限制 &apos;Default&apos; =&gt; &apos;&apos;,//这是默认方法 也就是不写类名时候 默认去找的类 &apos;GoodsRecord&apos; =&gt; \\App\\Repositories\\GoodsRepository::class, &apos;Picture&apos; =&gt; \\App\\Repositories\\PicturesRepository::class, &apos;Store&apos; =&gt; \\App\\Repositories\\StoresRepository::class, &apos;Goods&apos; =&gt; \\App\\Repositories\\GoodsRepository::class, &apos;GoodsRecord&apos; =&gt; \\App\\Repositories\\GoodsRecordsRepository::class, &apos;Response&apos; =&gt; \\App\\ZL\\ResponseLayout::class, &apos;Qrcode&apos; =&gt; \\App\\Repositories\\QrcodesRepository::class, &apos;User&apos; =&gt; \\App\\Repositories\\UsersRepository::class,); 以下是控制器中的使用示例 12345678public function bindRecord(Request $request)&#123; return \\Flow::setLastFunc([&apos;Response/flowReturn&apos;])-&gt;setParam($request-&gt;all())-&gt;flow([ [&apos;Store/getIdByNo&apos;], [&apos;User/bindRecord&apos;], [&apos;User/checkMemberExist&apos;], ])[&apos;response&apos;];&#125; 首先除了flow方法。别的方法调用都是返回对象本身 所以可以链式调用 以上是facade模式的调用再看一下这个详细的例子 1234567891011121314151617181920212223public function beforeStore($id, $data)&#123; $data[&apos;cover_url&apos;] = &apos;http://weiyicrm.oss-cn-shanghai.aliyuncs.com/ico-fuzhaung.png&apos;; $data[&apos;input_goods_no&apos;] = isset($data[&apos;goods_no&apos;])?$data[&apos;goods_no&apos;]:null; $data[&apos;id&apos;] = $id; //setParam方法是设置运行中的参数 可以是数组 或者是两个参数键值的形式 return \\Flow::setParam($data)-&gt;flow([ //flow为主运行方法 [&apos;Store/getOneId&apos;], // 数组第二个参数是array型 可以设置函数的额外参数 第三个参数int型 是一个缓存的时间值可以设置是否缓存 单位为分钟 [&apos;Qrcode/generateGoodsNoAndCreateQrcodeByNum&apos;,[&apos;created_pic&apos;=&gt;false]], [&apos;Picture/getIds&apos;], [&apos;Picture/getModelByIds&apos;], [&apos;Goods/getGoodsNo&apos;], [&apos;Goods/findByNo&apos;], [&apos;Goods/updateByStock&apos;], [&apos;Goods/updateBySell&apos;], [&apos;Goods/createOne&apos;], [&apos;Qrcode/bingQrcodeGoodsNo&apos;],// [&apos;Qrcode/bingQrcodeLabelNo&apos;],// [&apos;GoodsRecord/updateOne&apos;], [&apos;Response/flowReturn&apos;], ])[&apos;response&apos;];&#125; 此例子中并没有使用setLastFunc方法（用来设置最后运行方法的）需要注意的是缓存是用了类名+方法名+参数转成字符串的值作为缓存的键名。可以适用于一些场景 可以配合前面函数输出缓存的依据参数 配合使用应该还不错 最后看一下 几个方法的实例 了解下方法的编写注意方法中的参数都是通过方法容器自动传入的(变量名与参数名相同) 如果方法容器的参数数组中不存在并且没有默认值 会传入nullflow方法会把方法容器的parameters成员返回 也就是所有的参数 1234567891011121314这一用来返回最后的reponse数组的方法。 判断在别的方法中是否输出了错误码和错误信息public function flowReturn($res,$errcode,$errmsg,$msg)&#123; if(!$errcode)&#123; $data[&apos;status&apos;] = 1; $data[&apos;data&apos;] = $res; $data[&apos;msg&apos;] = $msg?$msg:&apos;Success&apos;; &#125;else&#123; $data[&apos;status&apos;] = $errcode; $data[&apos;data&apos;] = null; $data[&apos;msg&apos;] = $errmsg?$errmsg:&apos;Error&apos;; &#125; return [&apos;response&apos;=&gt;$data];&#125; 12345678910111213public function getOneId()&#123; $user = Auth::user(); if($user) &#123; $stores = $user-&gt;stores; if ($stores-&gt;count() == 1) &#123; //最后输出的数组 会合并入方法容器的参数数组中 之后的方法中 可以申明参数 只要变量名与参数名相同 就可以自动传入 return [&apos;store_id&apos;=&gt;$stores-&gt;first()-&gt;id]; &#125; &#125; //这里返回的skip是可以跳过之后的一些方法 直接运行想要的方法 可以作为报错后的处理 这里出错 所以返回了错误码和错误信息 return [&apos;skip&apos;=&gt;&apos;flowReturn&apos;,&apos;store_id&apos;=&gt;null,&apos;errcode&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;code&apos;],&apos;errmsg&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;msg&apos;]];&#125; 1234567891011public function getIdByNo($store_no)&#123; if($store_no)&#123; $store = $this-&gt;findBy(&apos;identifying&apos;,$store_no); if($store)&#123; return [&apos;store_id&apos;=&gt;$store-&gt;id]; &#125; &#125; //这里返回的next为false 会让方法容器不执行之后的方法。直接运行lastFunc（如果定义了的话）ps：可以把最后的返回参数处理函数定义为lastFunc return [&apos;next&apos;=&gt;false,&apos;store_id&apos;=&gt;null,&apos;errcode&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;code&apos;],&apos;errmsg&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;msg&apos;]];&#125; 有兴趣的小伙伴可以体验一下，也可以来github上提bug和问题，我会立刻改正","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"Linux下查看Nginx等的并发连接数和连接状态","slug":"Linux下查看Nginx等的并发连接数和连接状态","date":"2017-04-21T09:01:55.000Z","updated":"2021-11-19T03:41:15.350Z","comments":true,"path":"2017/04/21/Linux下查看Nginx等的并发连接数和连接状态/","link":"","permalink":"https://anyuzhe.github.io/2017/04/21/Linux下查看Nginx等的并发连接数和连接状态/","excerpt":"","text":"Linux下查看Nginx等的并发连接数和连接状态。 1、查看Web服务器（Nginx Apache）的并发请求数及其TCP连接状态：netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’或者： netstat -n | awk ‘/^tcp/ {++state[$NF]} END {for(key in state) print key,”t”,state[key]}’返回结果一般如下：LAST_ACK 5 （正在等待处理的请求数） SYN_RECV 30ESTABLISHED 1597 （正常数据传输状态）FIN_WAIT1 51FIN_WAIT2 504TIME_WAIT 1057 （处理完毕，等待超时结束的请求数）其他参数说明：CLOSED：无连接是活动的或正在进行 LISTEN：服务器在等待进入呼叫SYN_RECV：一个连接请求已经到达，等待确认SYN_SENT：应用已经开始，打开一个连接ESTABLISHED：正常数据传输状态FIN_WAIT1：应用说它已经完成FIN_WAIT2：另一边已同意释放ITMED_WAIT：等待所有分组死掉CLOSING：两边同时尝试关闭TIME_WAIT：另一边已初始化一个释放LAST_ACK：等待所有分组死掉2、查看Nginx运行进程数 ps -ef | grep nginx | wc -l返回的数字就是nginx的运行进程数，如果是apache则执行ps -ef | grep httpd | wc -l3、查看Web服务器进程连接数： netstat -antp | grep 80 | grep ESTABLISHED -c4、查看MySQL进程连接数： ps -axef | grep mysqld -c","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://anyuzhe.github.io/categories/计算机基础/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://anyuzhe.github.io/tags/nginx/"}]},{"title":"laravel 框架 源码解读 03 Pipeline.php 管道类","slug":"laravel_pipe_code_read","date":"2017-04-11T16:32:14.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/04/12/laravel_pipe_code_read/","link":"","permalink":"https://anyuzhe.github.io/2017/04/12/laravel_pipe_code_read/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205&lt;?phpnamespace Illuminate\\Pipeline;use Closure;use RuntimeException;use Illuminate\\Contracts\\Container\\Container;use Illuminate\\Contracts\\Pipeline\\Pipeline as PipelineContract;class Pipeline implements PipelineContract&#123; /** * The container implementation. * * @var \\Illuminate\\Contracts\\Container\\Container */ 服务容器实例 protected $container; /** * The object being passed through the pipeline. * * @var mixed */ 经过管道的数据 protected $passable; /** * The array of class pipes. * * @var array */ 管道类的数组 protected $pipes = []; /** * The method to call on each pipe. * * @var string */ 管道类中调用方法 protected $method = &apos;handle&apos;; /** * Create a new class instance. * * @param \\Illuminate\\Contracts\\Container\\Container|null $container * @return void */ 构造函数传入服务容器 public function __construct(Container $container = null) &#123; $this-&gt;container = $container; &#125; /** * Set the object being sent through the pipeline. * * @param mixed $passable * @return $this */ 初始化 经过管道的变量 public function send($passable) &#123; $this-&gt;passable = $passable; return $this; &#125; /** * Set the array of pipes. * * @param array|mixed $pipes * @return $this */ 设置管道类 public function through($pipes) &#123; $this-&gt;pipes = is_array($pipes) ? $pipes : func_get_args(); return $this; &#125; /** * Set the method to call on the pipes. * * @param string $method * @return $this */ 设置管道类的处理函数 public function via($method) &#123; $this-&gt;method = $method; return $this; &#125; /** * Run the pipeline with a final destination callback. * * @param \\Closure $destination * @return mixed */ 管道启动开始 public function then(Closure $destination) &#123; $pipeline = array_reduce( 反转管道类数组 依次调用的闭包 调用目标闭包的闭包 array_reverse($this-&gt;pipes), $this-&gt;carry(), $this-&gt;prepareDestination($destination) ); return $pipeline($this-&gt;passable); &#125; /** * Get the final piece of the Closure onion. * * @param \\Closure $destination * @return \\Closure */ 准备目标函数 返回一个闭包：目标闭包调用变量 protected function prepareDestination(Closure $destination) &#123; return function ($passable) use ($destination) &#123; return $destination($passable); &#125;; &#125; /** * Get a Closure that represents a slice of the application onion. * * @return \\Closure */ 返回一个闭包 调用 protected function carry() &#123; array_reduce() 函数向用户自定义函数发送数组中的值，并返回一个字符串。 注释：如果数组是空的且未传递 initial 参数，该函数返回 NULL 调用返回闭包 调用参数 第一个参数为 管道类 第二个参数为闭包 return function ($stack, $pipe) &#123; 调用返回闭包 调用参数 为传入的变量 用了管道类 和 闭包 return function ($passable) use ($stack, $pipe) &#123; if ($pipe instanceof Closure) &#123; 如果参数为闭包就直接调用闭包 第一次为初始化的闭包 // If the pipe is an instance of a Closure, we will just call it directly but // otherwise we&apos;ll resolve the pipes out of the container and call it with // the appropriate method and arguments, returning the results back out. return $pipe($passable, $stack); &#125; elseif (! is_object($pipe)) &#123; 如果参数不是对象 就解析 分成两个变量8 list($name, $parameters) = $this-&gt;parsePipeString($pipe); // If the pipe is a string we will parse the string and resolve the class out // of the dependency injection container. We can then build a callable and // execute the pipe function giving in the parameters that are required. $pipe = $this-&gt;getContainer()-&gt;make($name); $parameters = array_merge([$passable, $stack], $parameters); &#125; else &#123; // If the pipe is already an object we&apos;ll just make a callable and pass it to // the pipe as-is. There is no need to do any extra parsing and formatting // since the object we&apos;re given was already a fully instantiated object. $parameters = [$passable, $stack]; &#125; return $pipe-&gt;&#123;$this-&gt;method&#125;(...$parameters); &#125;; &#125;; &#125; /** * Parse full pipe string to get name and parameters. * * @param string $pipe * @return array */ protected function parsePipeString($pipe) &#123; list($name, $parameters) = array_pad(explode(&apos;:&apos;, $pipe, 2), 2, []); if (is_string($parameters)) &#123; $parameters = explode(&apos;,&apos;, $parameters); &#125; return [$name, $parameters]; &#125; /** * Get the container instance. * * @return \\Illuminate\\Contracts\\Container\\Container * @throws \\RuntimeException */ protected function getContainer() &#123; if (! $this-&gt;container) &#123; throw new RuntimeException(&apos;A container instance has not been passed to the Pipeline.&apos;); &#125; return $this-&gt;container; &#125;&#125; App\\Http\\Kernel; 有以下中间件 protected $middleware = [ \\Illuminate\\Foundation\\Http\\Middleware\\CheckForMaintenanceMode::class, \\Illuminate\\Foundation\\Http\\Middleware\\ValidatePostSize::class, \\App\\Http\\Middleware\\TrimStrings::class, \\Illuminate\\Foundation\\Http\\Middleware\\ConvertEmptyStringsToNull::class, ]; public function handle($request, Closure $next) { if ($this-&gt;app-&gt;isDownForMaintenance()) { $data = json_decode(file_get_contents($this-&gt;app-&gt;storagePath().&apos;/framework/down&apos;), true); throw new MaintenanceModeException($data[&apos;time&apos;], $data[&apos;retry&apos;], $data[&apos;message&apos;]); } return $next($request); } 中间价执行函数 传入经过管道的变量 和一个执行闭包","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"方法容器-流程控制编写模式 控制器编写模式 3","slug":"naodong_3","date":"2017-04-11T15:30:57.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2017/04/11/naodong_3/","link":"","permalink":"https://anyuzhe.github.io/2017/04/11/naodong_3/","excerpt":"","text":"为什么我不再使用MVC框架 这篇文章中的 中心思想是 1234567该模式的反应型和函数式结构使得功能重放（replay）和单元测试变得非常容易。SAM模式完全改变了前端架构的范式，因为根据TLA+的基础理念，业务逻辑可以清晰地描述为： 1 Action是纯函数 2 CRUD操作放在Model中 3 状态控制自动化的Action 这个引入我的这个流程中是使得控制器中的方法流程 类似于 闭包 管道的形式调用 可以随时在中间中断 待更新代码 加入管道模式 和闭包调用模式","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"laravel 框架 源码解读 02 index.php 文件剩余代码","slug":"laravel_read_code2","date":"2017-04-05T17:24:02.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/04/06/laravel_read_code2/","link":"","permalink":"https://anyuzhe.github.io/2017/04/06/laravel_read_code2/","excerpt":"","text":"$app = require_once DIR.’/../bootstrap/app.php’;引入laravel的启动应用文件 实际为服务容器的创建和绑定的过程 1234567891011121314151617181920212223242526&lt;?php创建服务容器实例 参数为项目根目录地址$app = new Illuminate\\Foundation\\Application( realpath(__DIR__.&apos;/../&apos;));为服务容器绑定了 一个单例 此为http核心类$app-&gt;singleton( Illuminate\\Contracts\\Http\\Kernel::class, App\\Http\\Kernel::class);为服务容器绑定了 一个单例 此为命令行核心类$app-&gt;singleton( Illuminate\\Contracts\\Console\\Kernel::class, App\\Console\\Kernel::class);为服务容器绑定了 一个单例 此为异常处理类$app-&gt;singleton( Illuminate\\Contracts\\Debug\\ExceptionHandler::class, App\\Exceptions\\Handler::class);返回容器对象return $app; 以下是入口文件index.php剩下的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061从服务容器中得到刚才绑定的类 make会创建一个对象并且 如果是单例模式 只会创建一次看的出是http的核心类 参数是laravel的接口类名 在刚才的app文件中已经对这个接口进行了绑定$kernel = $app-&gt;make(Illuminate\\Contracts\\Http\\Kernel::class);http核心类处理请求 得到response对象 实际的kernel类在vendor/laravel/framework/src/Illuminate/Foundation/Http 文件夹下$response = $kernel-&gt;handle( $request = Illuminate\\Http\\Request::capture() 初始化并创建了一个request类 就是symfony的组件request);/*可以看一下代码 就是对请求的处理 也是编写代码执行的地方 public function handle($request)&#123; try &#123; $request-&gt;enableHttpMethodParameterOverride(); $response = $this-&gt;sendRequestThroughRouter($request); &#125; catch (Exception $e) &#123; $this-&gt;reportException($e); $response = $this-&gt;renderException($request, $e); &#125; catch (Throwable $e) &#123; $this-&gt;reportException($e = new FatalThrowableError($e)); $response = $this-&gt;renderException($request, $e); &#125; event(new Events\\RequestHandled($request, $response)); return $response;&#125; protected function sendRequestThroughRouter($request)&#123; $this-&gt;app-&gt;instance(&apos;request&apos;, $request);把request对象 绑定到服务容器的这个key中 Facade::clearResolvedInstance(&apos;request&apos;); $this-&gt;bootstrap(); 为让服务容器 执行 核心类的初始化数组。其中有很多类 ／* \\Illuminate\\Foundation\\Bootstrap\\LoadEnvironmentVariables::class, \\Illuminate\\Foundation\\Bootstrap\\LoadConfiguration::class, \\Illuminate\\Foundation\\Bootstrap\\HandleExceptions::class, \\Illuminate\\Foundation\\Bootstrap\\RegisterFacades::class, \\Illuminate\\Foundation\\Bootstrap\\RegisterProviders::class, \\Illuminate\\Foundation\\Bootstrap\\BootProviders::class, *／ 创建了一个管道类 执行了核心的中间件。再分发到了路由类 又有一个管道类 处理了一波中间件 这里很复杂 也是laravel被称为黑盒的原因 return (new Pipeline($this-&gt;app)) -&gt;send($request) -&gt;through($this-&gt;app-&gt;shouldSkipMiddleware() ? [] : $this-&gt;middleware) -&gt;then($this-&gt;dispatchToRouter());&#125;*/response对象 执行发送http的回应方法$response-&gt;send();$kernel-&gt;terminate($request, $response); 命令行的处理方法","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"laravel 框架 源码解读 01 bootstrap 引入composer","slug":"laravel_read_code","date":"2017-04-05T16:30:17.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/04/06/laravel_read_code/","link":"","permalink":"https://anyuzhe.github.io/2017/04/06/laravel_read_code/","excerpt":"","text":"访问 public目录下的index.php 入口文件 require DIR.’/../bootstrap/autoload.php’;在这里引入了框架 类自动加载的文件 在DIR.’/../bootstrap/autoload.php中 实际 引入了 require DIR.’/../vendor/autoload.php’; 接下来是composer的autoload.php文件中的故事 require_once DIR . ‘/composer/autoload_real.php’; return ComposerAutoloaderInit588ef64a8f8e0cc101a16ea4a5b588bf::getLoader(); 执行了getLoader这个静态方法 其中的代码是 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596private static $loader;public static function loadClassLoader($class)&#123; 如果是访问自动加载的类 就去引入相应的加载类 if (&apos;Composer\\Autoload\\ClassLoader&apos; === $class) &#123; require __DIR__ . &apos;/ClassLoader.php&apos;; &#125;&#125;public static function getLoader()&#123; 此处为防止方法重复运行 if (null !== self::$loader) &#123; return self::$loader; &#125; 为php注册自动加载类的方法 此处注册的composer的自动加载类 也就是当前类的上面的loadClassLoader方法 spl_autoload_register(array(&apos;ComposerAutoloaderInit588ef64a8f8e0cc101a16ea4a5b588bf&apos;, &apos;loadClassLoader&apos;), true, true); 自动加载的类 新建对象 self::$loader = $loader = new \\Composer\\Autoload\\ClassLoader(); 去掉上面的自动加载方法注册 spl_autoload_unregister(array(&apos;ComposerAutoloaderInit588ef64a8f8e0cc101a16ea4a5b588bf&apos;, &apos;loadClassLoader&apos;)); 判断php版本号大于50600 并且不是在hhvm环境中 $useStaticLoader = PHP_VERSION_ID &gt;= 50600 &amp;&amp; !defined(&apos;HHVM_VERSION&apos;); if ($useStaticLoader) &#123; 如果是静态加载 就引入静态加载类 require_once __DIR__ . &apos;/autoload_static.php&apos;; call_user_func(\\Composer\\Autoload\\ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::getInitializer($loader)); ／* 此为上面的方法作用的表示 返回一个闭包。闭包的作用是给自动加载类 动态绑定具体的自动加载方法 执行此闭包 public static function getInitializer(ClassLoader $loader) &#123; return \\Closure::bind(function () use ($loader) &#123; $loader-&gt;prefixLengthsPsr4 = ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::$prefixLengthsPsr4; $loader-&gt;prefixDirsPsr4 = ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::$prefixDirsPsr4; $loader-&gt;prefixesPsr0 = ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::$prefixesPsr0; $loader-&gt;classMap = ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::$classMap; &#125;, null, ClassLoader::class); &#125; *／ &#125; else &#123; 动态的加载类 引入 命名空间文件 是一个二维数组 保存了命名空间到 具体文件夹的对应关系 $map = require __DIR__ . &apos;/autoload_namespaces.php&apos;; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;set($namespace, $path); &#125; psr4格式的 文件夹对应关系 $map = require __DIR__ . &apos;/autoload_psr4.php&apos;; foreach ($map as $namespace =&gt; $path) &#123; $loader-&gt;setPsr4($namespace, $path); &#125; 具体的类到文件的对应关系 $classMap = require __DIR__ . &apos;/autoload_classmap.php&apos;; if ($classMap) &#123; $loader-&gt;addClassMap($classMap); &#125; &#125; $loader-&gt;register(true); 实际调用了。 spl_autoload_register(array($this, &apos;loadClass&apos;), true, $prepend); 进行注册 loadClass方法就是在类的自动加载函数的时机使用方法 以下代码 就是为了引入自动加载的文件 不解释了 if ($useStaticLoader) &#123; $includeFiles = Composer\\Autoload\\ComposerStaticInit588ef64a8f8e0cc101a16ea4a5b588bf::$files; &#125; else &#123; $includeFiles = require __DIR__ . &apos;/autoload_files.php&apos;; &#125; foreach ($includeFiles as $fileIdentifier =&gt; $file) &#123; composerRequire588ef64a8f8e0cc101a16ea4a5b588bf($fileIdentifier, $file); &#125; return $loader;&#125; function composerRequire588ef64a8f8e0cc101a16ea4a5b588bf($fileIdentifier, $file)&#123; if (empty($GLOBALS[&apos;__composer_autoload_files&apos;][$fileIdentifier])) &#123; require $file; $GLOBALS[&apos;__composer_autoload_files&apos;][$fileIdentifier] = true; &#125;&#125; composer的自动加载完毕 以上主要篇幅都是composer中的自动加载代码 与laravel 其实无关 以后才是laravel的真正开始","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"appium 相关文章 地址记录","slug":"appium记录","date":"2017-04-03T15:13:57.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2017/04/03/appium记录/","link":"","permalink":"https://anyuzhe.github.io/2017/04/03/appium记录/","excerpt":"","text":"appium github appium 下载地址 Appium使用 及Appium PHP client 进行手机自动化测试 appium/php-client Appium 中文文档 appium简明教程 psthon 进阶指南","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"方法容器-流程控制编写模式 控制器编写模式 2","slug":"naodong_2","date":"2017-04-03T14:29:11.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2017/04/03/naodong_2/","link":"","permalink":"https://anyuzhe.github.io/2017/04/03/naodong_2/","excerpt":"","text":"第二部分 是思考时间 主要考虑 1中的思想的代码架构 我这个模式和Repository模式 有点像 都是把业务的方法分层甚至可以说是对Repository模式的优化 或者说更彻底的运用仓库模式把仓库的功能提升，仓库不在是仓库 是一个控制流程 我的模式目的是两个 代码优雅 代码量减少(单个方法是增多 但是总的来看应该是减少的) 以下是把Repository模式融入进我的模式的特点 方法容器中有仓库类仓库类中有各自的方法 方法容器中调用的是仓库类的方法把方法内聚 同种方法写在同一个仓库类中可以直接使用别人的repository的包为基类的类 作为我的仓库类 ……包已经写完laravel-function-flow 使用代码为 首先用composer加载包 composer require anyuzhe/laravel-function-flow dev-master 在配置文件config/app.php的服务容器数组中加入 \\Anyuzhe\\LaravelFunctionFlow\\FunctionFlowServiceProvider::class, 在门面数组中加入 ‘Flow’ =&gt; \\Anyuzhe\\LaravelFunctionFlow\\FlowFacade::class, 执行命令 生成配置文件 php artisan funcFlow:publish会在config文件夹中生成function-flow.php文件可在里面配置仓库类 类似如下 123456789101112return array(// &apos;Base&apos;=&gt;BaseController::class 类似这样的key value定义类 名称和位置 无任何限制 &apos;Default&apos; =&gt; &apos;&apos;, &apos;GoodsRecord&apos; =&gt; \\App\\Repositories\\GoodsRepository::class, &apos;Picture&apos; =&gt; \\App\\Repositories\\PicturesRepository::class, &apos;Store&apos; =&gt; \\App\\Repositories\\StoresRepository::class, &apos;Goods&apos; =&gt; \\App\\Repositories\\GoodsRepository::class, &apos;GoodsRecord&apos; =&gt; \\App\\Repositories\\GoodsRecordsRepository::class, &apos;Response&apos; =&gt; \\App\\ZL\\ResponseLayout::class, &apos;Qrcode&apos; =&gt; \\App\\Repositories\\QrcodesRepository::class, &apos;User&apos; =&gt; \\App\\Repositories\\UsersRepository::class,); 以下是控制器中的使用示例 12345678public function bindRecord(Request $request)&#123; return \\Flow::setLastFunc([&apos;Response/flowReturn&apos;])-&gt;setParam($request-&gt;all())-&gt;flow([ [&apos;Store/getIdByNo&apos;], [&apos;User/bindRecord&apos;], [&apos;User/checkMemberExist&apos;], ])[&apos;response&apos;];&#125; 首先除了flow方法。别的方法调用都是返回对象本身 所以可以链式调用 以上是facade方式的调用再看一下这个详细的例子 12345678910111213141516171819202122public function beforeStore($id, $data)&#123; $data[&apos;cover_url&apos;] = &apos;http://weiyicrm.oss-cn-shanghai.aliyuncs.com/ico-fuzhaung.png&apos;; $data[&apos;input_goods_no&apos;] = isset($data[&apos;goods_no&apos;])?$data[&apos;goods_no&apos;]:null; $data[&apos;id&apos;] = $id; //setParam方法是设置运行中的参数 可以是数组 或者是两个参数键值的形式 return \\Flow::setParam($data)-&gt;flow([ //flow为主运行方法 [&apos;Store/getOneId&apos;], // 数组第二个参数可以设置函数的额外参数 第三个参数是一个缓存的时间值可以设置是否缓存 单位为分钟 [&apos;Qrcode/generateGoodsNoAndCreateQrcodeByNum&apos;,[&apos;created_pic&apos;=&gt;false]], [&apos;Picture/getIds&apos;], [&apos;Picture/getModelByIds&apos;], [&apos;Goods/getGoodsNo&apos;], [&apos;Goods/findByNo&apos;], [&apos;Goods/updateByStock&apos;], [&apos;Goods/updateBySell&apos;], [&apos;Goods/createOne&apos;], [&apos;Qrcode/bingQrcodeGoodsNo&apos;],// [&apos;Qrcode/bingQrcodeLabelNo&apos;],// [&apos;GoodsRecord/updateOne&apos;], [&apos;Response/flowReturn&apos;], ])[&apos;response&apos;]; 此例子中并没有使用setLastFunc方法（用来设置最后运行方法的）需要注意的是缓存是用了类名+方法名+参数转成字符串的值作为缓存的键名。可以适用于一些场景 可以配合函数输出缓存的依据参数 配合使用应该还不错 最后看一下 几个方法的实例 了解下方法的编写注意方法中的参数都是通过方法容器自动传入的 如果方法容器的参数数组中不存在并且没有默认值 会传入nullflow方法会把方法容器的parameters成员返回 也就是所有的参数 1234567891011121314这一用来返回最后的reponse数组的方法。 判断在别的方法中是否输出了错误码和错误信息public function flowReturn($res,$errcode,$errmsg,$msg)&#123; if(!$errcode)&#123; $data[&apos;status&apos;] = 1; $data[&apos;data&apos;] = $res; $data[&apos;msg&apos;] = $msg?$msg:&apos;Success&apos;; &#125;else&#123; $data[&apos;status&apos;] = $errcode; $data[&apos;data&apos;] = null; $data[&apos;msg&apos;] = $errmsg?$errmsg:&apos;error&apos;; &#125; return [&apos;response&apos;=&gt;$data];&#125; 12345678910111213public function getOneId()&#123; $user = Auth::user(); if($user) &#123; $stores = $user-&gt;stores; if ($stores-&gt;count() == 1) &#123; //最后输出的数组 会合并入方法容器的参数数组中 之后的方法中 可以申明参数 只要变量名与参数名相同 就可以自动传入 return [&apos;store_id&apos;=&gt;$stores-&gt;first()-&gt;id]; &#125; &#125; //这里返回的skip是可以跳过之后的一些方法 直接运行想要的方法 可以作为报错后的处理 这里出错 所以返回了错误码和错误信息 return [&apos;skip&apos;=&gt;&apos;flowReturn&apos;,&apos;store_id&apos;=&gt;null,&apos;errcode&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;code&apos;],&apos;errmsg&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;msg&apos;]];&#125; 1234567891011public function getIdByNo($store_no)&#123; if($store_no)&#123; $store = $this-&gt;findBy(&apos;identifying&apos;,$store_no); if($store)&#123; return [&apos;store_id&apos;=&gt;$store-&gt;id]; &#125; &#125; //这里返回的next为false 会让方法容器不执行之后的方法。直接运行lastFunc（如果定义了的话）ps：可以把最后的返回参数处理函数定义为lastFunc return [&apos;next&apos;=&gt;false,&apos;store_id&apos;=&gt;null,&apos;errcode&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;code&apos;],&apos;errmsg&apos;=&gt;ErrorCode::$canNotFindStoreError[&apos;msg&apos;]];&#125;","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"方法容器-流程控制编写模式    控制器编写模式  1","slug":"naodong_1","date":"2017-04-03T13:21:01.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/04/03/naodong_1/","link":"","permalink":"https://anyuzhe.github.io/2017/04/03/naodong_1/","excerpt":"","text":"mvc模式里的 c 控制器 每次编写代码的 其中有一大部分高度复用的如果把这部分代码 解耦出来 成为可以高度复用的方法 可以大大减少代码量 如果一个方法容器 有着许多的辅助方法 流程方法而在写控制器方法的时候就可以只要写方法流程 就可以让方法容器依次调用这些方法 这样就可以大大减少代码量 可以让控制器的代码 非常优雅 so 这当中会有许多的问题 需要解决 问题1 谁去依次调用这些方法呢 所以需要一个方法容器去一次依次调用 问题2 方法放在哪里，方法的依赖变量和输出放在哪 为什么叫方法容器，就是因为需要放置方法，和方法的依赖和输出变量，在最后一个方法结束后 把所有输出变量数据返回容器需要用到反射，去解析方法的依赖变量 从方法的输出变量 或者mvc框架的系统容器中 得到以来依赖的类方法依赖的变量(也就是参数) 可以靠前面的方法输出，也可以穿入 所以方法的运行顺序很重要 问题3 效率问题 暂时想到的是 可以设置 过程是否为 缓存过程 如果是缓存的过程 第二次执行 就会直接或者给出方法的输出结果 理想的控制器方法代码示例 123456789reture FunctionContainer::Pipeline([ [ &apos;modelGetAuthLimit&apos;,[额外的变量数组]，[输出是否缓存]], [ &apos;modelGetSearch&apos;], [ &apos;modelGetSort&apos;], [ &apos;modelFind&apos;], [ &apos;modelFindLoads&apos;], [ &apos;modelByAfterFind&apos;], [ &apos;retureResponse&apos;], ]); 思考的是 这种模式到底有没有好的应用场景灵感的来源是我在同一个控制器的不同方法中 用了许多的重复方法 所以改成了用另外一个方法去调用重复的方法 这样代码会比较优雅我目前在控制器中的代码并没有 完全用上上面讲的，因为上面说的我还没开始写，首先要考虑到应用场景，不能做过多的设计 123456789101112131415161718192021222324252627282930public function show($id,Request $request) &#123; Context::set([&apos;id&apos;=&gt;$id]); $data = $this-&gt;modelPipeline([ &apos;modelGetAuthLimit&apos;, &apos;modelFindById&apos;, &apos;modelFindLoads&apos;, &apos;modelByAfterFind&apos;, ]); return responseZK(1,$data); &#125; public function find(Request $request) &#123; $data = $this-&gt;modelPipeline([ &apos;modelGetAuthLimit&apos;, &apos;modelGetSearch&apos;, &apos;modelGetSort&apos;, &apos;modelFind&apos;, &apos;modelFindLoads&apos;, &apos;modelByAfterFind&apos;, ]); if($data) &#123; return responseZK(1, $data); &#125;else&#123; return responseZK(ErrorCode::$modelCanNotFindError[&apos;code&apos;], [],ErrorCode::$modelCanNotFindError[&apos;msg&apos;]); &#125; &#125;","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"laravel 好用的库","slug":"laravel-好用的库","date":"2017-03-29T01:20:39.000Z","updated":"2021-11-19T03:41:15.352Z","comments":true,"path":"2017/03/29/laravel-好用的库/","link":"","permalink":"https://anyuzhe.github.io/2017/03/29/laravel-好用的库/","excerpt":"","text":"laravel - oss组件 laravel ide helper Laravel Repositories","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"解锁 Redis 锁的正确姿势","slug":"php_redis_lock","date":"2017-03-23T13:18:23.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/03/23/php_redis_lock/","link":"","permalink":"https://anyuzhe.github.io/2017/03/23/php_redis_lock/","excerpt":"","text":"解锁redis锁的正确姿势 redis是php的好朋友，在php写业务过程中，有时候会使用到锁的概念，同时只能有一个人可以操作某个行为。这个时候我们就要用到锁。锁的方式有好几种，php不能在内存中用锁，不能使用zookeeper加锁，使用数据库做锁又消耗比较大，这个时候我们一般会选用redis做锁机制。 1234567891011121314151617181920212223242526$token = rand(1, 100000);function lock() &#123; return Redis::set(&quot;my:lock&quot;, $token, &quot;nx&quot;, &quot;ex&quot;, 10);&#125;上面的代码把my:lock设置为1，当且仅当这个lock不存在的时候，设置完成之后设置过期时间为10。获取锁的机制是对了，但是删除锁的机制直接使用del是不对的。因为有可能导致误删别人的锁的情况。//伪代码function unlock() &#123; $script = `if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1]then return redis.call(&quot;del&quot;,KEYS[1])else return 0end ` return Redis::eval($script, &quot;my:lock&quot;, $token)&#125;if (lock()) &#123; // do something unlock();&#125; 这里的token是一个随机数，当lock的时候，往redis的my:lock中存的是这个token，unlock的时候，先get一下lock中的token，如果和我要删除的token是一致的，说明这个锁是之前我set的，否则的话，说明这个锁已经过期，是别人set的，我就不应该对它进行任何操作。","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"利用 Facebook的webDriver  phantomjs驱动 做一个爬虫例子","slug":"php_webDriver_phantomjs","date":"2017-03-22T07:43:57.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/03/22/php_webDriver_phantomjs/","link":"","permalink":"https://anyuzhe.github.io/2017/03/22/php_webDriver_phantomjs/","excerpt":"","text":"利用 Facebook webDriver phantomjs驱动 可以不打开浏览器的情况下 进行页面渲染的web测试和爬虫ps:应该更适合爬虫 为了做一个demo 决定爬一下66影视的电影资源 开启服务器 ./phantomjs –webdriver=127.0.0.1:8910phantomjs说明Facebook webDriver 是一种 Selenium 的php实现相应的方法api可以参照 别的语言 的Selenium的实现 方法名字完全一样 基本的使用例子 1234567891011121314151617181920require_once __DIR__ . &quot;/vendor/autoload.php&quot;;use \\Facebook\\WebDriver\\Remote\\WebDriverCapabilityType;use \\Facebook\\WebDriver\\Remote\\RemoteWebDriver;use \\Facebook\\WebDriver\\WebDriverDimension;$host = &apos;127.0.0.1:8910&apos;;$capabilities = array( WebDriverCapabilityType::BROWSER_NAME =&gt; &apos;phantomjs&apos;, &apos;phantomjs.page.settings.userAgent&apos; =&gt; &apos;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:25.0) Gecko/20100101 Firefox/25.0&apos;,);$driver = RemoteWebDriver::create($host, $capabilities, 5000);$window = new WebDriverDimension(1024, 768);$driver-&gt;manage()-&gt;window()-&gt;setSize($window);$driver-&gt;get(&apos;https://www.google.ru/&apos;);$driver-&gt;takeScreenshot(&apos;/tmp/screen.png&apos;);$driver-&gt;quit();","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"python windows 窗口自动化 操作 相关文章保存记录","slug":"python_win32_log","date":"2017-03-19T09:11:28.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/03/19/python_win32_log/","link":"","permalink":"https://anyuzhe.github.io/2017/03/19/python_win32_log/","excerpt":"","text":"百度 python windos 模拟按键 如何利用Python和win32编程避免重复性体力劳动 Python&amp;按键精灵自动化 用pywin32实现windows模拟鼠标及键盘动作 Python调用win32api","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"python","slug":"python","permalink":"https://anyuzhe.github.io/tags/python/"}]},{"title":"设置mysql主从库数据同步的配置方法","slug":"设置mysql主从库数据同步的配置方法","date":"2017-03-14T14:34:57.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/03/14/设置mysql主从库数据同步的配置方法/","link":"","permalink":"https://anyuzhe.github.io/2017/03/14/设置mysql主从库数据同步的配置方法/","excerpt":"","text":"主机（master）配置：1.修改mysql配置文件my.ini在[mysqld]标签下添加以下几行 123456789log-bin=名字 这个是开启二进制日志 如果名字mysql-bin 生成的二进制日志名为:mysql-bin.000001server-id=你设置的数值 这个是唯一的id标识 默认为1 不能和从服务器重复binlog-do-db=数据库名 这个是你要记录的数据库名binlog-ignore-db=数据库名 指定不对哪个数据库记录二进制日志 不是必需要设的max_allowed_packet=消息缓冲区的大小 这个数值主从设置的要一致最好设置大点 如:1G 使用命令行查看方式 show variables like &apos;%max_allowed_packet%&apos;; 2.为从服务器添加mysql账户并配置权限 使用cmd命令进入mysql 输入进行权限设置 123GRANT FILE ON *.* TO ‘backup’@&apos;192.168.0.3&apos; IDENTIFIED BY ‘1234’; GRANT REPLICATION SLAVE ON *.* TO ‘backup’@&apos;193.168.0.3&apos; IDENTIFIED BY ‘1234’; 这个账号和密码需有相应的权限如：从服务器ip使用此账号和密码可以连接到主服务器的数据库 3.记录File 及Position 项的值 重启mysql，使用show master status;查看主服务器状态，记录File 及Position 项的值，以便之后对从服务器进行配置。 从库（slave）配置： 1.修改mysql配置文件my.ini在[mysqld]标签下添加以下面一行： max_allowed_packet=消息缓冲区的大小 这个数值主从设置的要一致最好设置大点 如:1G 使用命令行查看方式 show variables like ‘%max_allowed_packet%’; server-id=你设置的数值 这个是唯一的id标识 默认为2 不能和主服务器重复 replicate-do-db=数据库名 这个是你要读取的数据库名 2.重启mysql数据库并设置相关参数 使用cmd 命令进入mysql 输入命令 change master to master_host=’主服务器ip地址’,master_port=主服务器端口,master_user=’设置的主服务器账号’,master_password=’主服务器密码’,master_log_file=’二进制日志名File’,master_log_pos=Position 项; 最后输入命令查看是否配置正确 SHOW SLAVE STATUS\\G 如果看到Slave_IO_Running: Yes 和 Slave_SQL_Running: Yes 正说明配置正确 停止复制数据需在从服务器命令行下输入 stop slave; 开启复制数据 start slave; —————————————-补充和出错的可能———————————————-一、需要把正式环境的数据导出一份到测试数据库 这个有几种办法，可以使用master/slave同步，也可以导出成SQL，然后再倒入。我喜欢导入/导出的方式。假设 192.168.0.10是master，192.168.0.11-14是slave。 #mysql -h192.168.0.10 -P3306 -uroot -ppassword databasename &gt; /home/xieping/data.sql #mysql -h192.168.0.11 -P3306 -uroot -ppassword databasename &lt; /home/xieping/data.sql 上面的命令要相对简单一些，也可以使用mysqldump命令，或者tar命令。 导出后再设置slave，参考下面的第二节。 二、需要添加一个slave 添加slave设置好my.conf就可以了。现在问题是在同步的过程中，IO部分完成了，但是SQL部分一直报错。 使用 #stop slave; #set GLOBAL SQL_SLAVE_SKIP_COUNTER=1; #start slave; 这种操作还是报错中断。 这种情况需要查看master的状态。 #mysql -h192.168.0.10 -uroot -p mysql&gt; show master status\\G; *** 1. row *** File: mysql-bin.000012 Position: 108822735 Binlog_Do_DB:Binlog_Ignore_DB: 1 row in set (0.00 sec) ERROR: No query specified 通过该命令获得File和Position，在slave中有用。 #mysql -h192.168.0.11 -uroot -p mysql&gt;stop slave; mysql&gt;change master to &gt;Master_Log_File = ‘mysql-bin.000012’, &gt;Master_Log_Pos = ‘108822735’; mysql&gt;show slave status\\G; *** 1. row *** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.0.10 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000012 Read_Master_Log_Pos: 108942588 Relay_Log_File: localhost-relay-bin.000035 Relay_Log_Pos: 22317781 Relay_Master_Log_File: mysql-bin.000012 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: databasename Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 108942317 Relay_Log_Space: 22318211 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 5Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: 1 row in set (0.00 sec) ERROR: No query specified 现在就正常了， Seconds_Behind_Master: 5 表明slave比master略有延迟。 三、更换master 更换master如果通过修改my.conf的话比较麻烦。不但要重启mysql进程，而且还不一定成功。可以通过 mysql&gt; stop slave; mysql&gt; reset slave; mysql&gt;start slave; 不过这样一来就重置了更新进度，更新会从头开始。 而是要change master to命令则可以通过命令设置，但这个命令不会影响my.conf文件，重启mysql后，设置就无效了。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/tags/mysql/"}]},{"title":"php的特点和运行机制","slug":"php的特点和运行机制","date":"2017-03-12T13:55:05.000Z","updated":"2021-11-19T03:41:15.354Z","comments":true,"path":"2017/03/12/php的特点和运行机制/","link":"","permalink":"https://anyuzhe.github.io/2017/03/12/php的特点和运行机制/","excerpt":"","text":"php是一种适用于web后端开发的动态语言或者说是用c语言实现的大量组件的软件框架 为了更好得用好php首先要了解php的底层 内存管理,框架模型值得我们借鉴通过拓展开发,能实现更多更强大的功能,优化程序的性能 1 PHP的设计理念及特点 多进程模型：由于PHP是多进程模型，不同请求间互不干涉，这样保证了一个请求挂掉不会对全盘服务造成影响，当然，随着时代发展，PHP也早已支持多线程模型。 弱类型语言：和C/C++、Java、C#等语言不同，PHP是一门弱类型语言。一个变量的类型并不是一开始就确定不变，运行中才会确定并可能发生隐式或显式的类型转换，这种机制的灵活性在web开发中非常方便、高效，具体会在后面PHP变量中详述。 引擎(Zend)+组件(ext)的模式降低内部耦合。 中间层(sapi)隔绝web server和PHP。 语法简单灵活，没有太多规范。缺点导致风格混杂，但再差的程序员也不会写出太离谱危害全局的程序。 2 PHP的四层体系PHP的核心架构如下图：从图上可以看出，PHP从下到上是一个4层体系： Zend引擎：Zend整体用纯C实现，是PHP的内核部分，它将PHP代码翻译（词法、语法解析等一系列编译过程）为可执行opcode的处理并实现相应的处理方法、实现了基本的数据结构（如hashtable、oo）、内存分配及管理、提供了相应的api方法供外部调用，是一切的核心，所有的外围功能均围绕Zend实现。 Extensions：围绕着Zend引擎，extensions通过组件式的方式提供各种基础服务，我们常见的各种内置函数（如array系列）、标准库等都是通过extension来实现，用户也可以根据需要实现自己的extension以达到功能扩展、性能优化等目的（如贴吧正在使用的PHP中间层、富文本解析就是extension的典型应用）。 Sapi：Sapi全称是Server Application Programming Interface，也就是服务端应用编程接口，Sapi通过一系列钩子函数，使得PHP可以和外围交互数据，这是PHP非常优雅和成功的一个设计，通过sapi成功的将PHP本身和上层应用解耦隔离，PHP可以不再考虑如何针对不同应用进行兼容，而应用本身也可以针对自己的特点实现不同的处理方式。 上层应用：这就是我们平时编写的PHP程序，通过不同的sapi方式得到各种各样的应用模式，如通过webserver实现web应用、在命令行下以脚本方式运行等等。 如果PHP是一辆车，那么车的框架就是PHP本身，Zend是车的引擎（发动机），Ext下面的各种组件就是车的轮子，Sapi可以看做是公路，车可以跑在不同类型的公路上，而一次PHP程序的执行就是汽车跑在公路上。因此，我们需要：性能优异的引擎+合适的车轮+正确的跑道。 3 Sapi如前所述，Sapi通过通过一系列的接口，使得外部应用可以和PHP交换数据并可以根据不同应用特点实现特定的处理方法，我们常见的一些sapi有： apache2handler：这是以apache作为webserver，采用mod_PHP模式运行时候的处理方式，也是现在应用最广泛的一种。 cgi：这是webserver和PHP直接的另一种交互方式，也就是大名鼎鼎的fastcgi协议，在最近今年fastcgi+PHP得到越来越多的应用，也是异步webserver所唯一支持的方式。 cli：命令行调用的应用模式 4 PHP的执行流程&amp;opcode我们先来看看PHP代码的执行所经过的流程。从图上可以看到，PHP实现了一个典型的动态语言执行过程：拿到一段代码后，经过词法解析、语法解析等阶段后，源程序会被翻译成一个个指令(opcodes)，然后ZEND虚拟机顺次执行这些指令完成操作。PHP本身是用C实现的，因此最终调用的也都是C的函数，实际上，我们可以把PHP看做是一个C开发的软件。 PHP的执行的核心是翻译出来的一条一条指令，也即opcode。 Opcode是PHP程序执行的最基本单位。一个opcode由两个参数(op1,op2)、返回值和处理函数组成。PHP程序最终被翻译为一组opcode处理函数的顺序执行。 常见的几个处理函数： 123456ZEND_ASSIGN_SPEC_CV_CV_HANDLER : 变量分配 （$a=$b）ZEND_DO_FCALL_BY_NAME_SPEC_HANDLER：函数调用ZEND_CONCAT_SPEC_CV_CV_HANDLER：字符串拼接 $a.$bZEND_ADD_SPEC_CV_CONST_HANDLER: 加法运算 $a+2ZEND_IS_EQUAL_SPEC_CV_CONST：判断相等 $a==1ZEND_IS_IDENTICAL_SPEC_CV_CONST：判断相等 $a===1 5 HashTable — 核心数据结构HashTable是zend的核心数据结构，在PHP里面几乎并用来实现所有常见功能，我们知道的PHP数组即是其典型应用，此外，在zend内部，如函数符号表、全局变量等也都是基于hash table来实现。 PHP的hash table具有如下特点： 支持典型的key-&gt;value查询 可以当做数组使用 添加、删除节点是O（1）复杂度 key支持混合类型：同时存在关联数组合索引数组 Value支持混合类型：array (“string”,2332) 支持线性遍历：如foreach Zend hash table实现了典型的hash表散列结构，同时通过附加一个双向链表，提供了正向、反向遍历数组的功能。其结构如下图： 可以看到，在hash table中既有key-&gt;value形式的散列结构，也有双向链表模式，使得它能够非常方便的支持快速查找和线性遍历。 散列结构：Zend的散列结构是典型的hash表模型，通过链表的方式来解决冲突。需要注意的是zend的hash table是一个自增长的数据结构，当hash表数目满了之后，其本身会动态以2倍的方式扩容并重新元素位置。初始大小均为8。另外，在进行key-&gt;value快速查找时候，zend本身还做了一些优化，通过空间换时间的方式加快速度。比如在每个元素中都会用一个变量nKeyLength标识key的长度以作快速判定。 双向链表：Zend hash table通过一个链表结构，实现了元素的线性遍历。理论上，做遍历使用单向链表就够了，之所以使用双向链表，主要目的是为了快速删除，避免遍历。Zend hash table是一种复合型的结构，作为数组使用时，即支持常见的关联数组也能够作为顺序索引数字来使用，甚至允许2者的混合。 PHP关联数组：关联数组是典型的hash_table应用。一次查询过程经过如下几步（从代码可以看出，这是一个常见的hash查询过程并增加一些快速判定加速查找。）： 12345678910getKeyHashValue h;index = n &amp; nTableMask;Bucket *p = arBucket[index];while (p) &#123; if ((p-&gt;h == h) &amp; (p-&gt;nKeyLength == nKeyLength)) &#123; RETURN p-&gt;data; &#125; p=p-&gt;next;&#125;RETURN FALTURE; *PHP索引数组：索引数组就是我们常见的数组，通过下标访问。例如 $arr[0]，Zend HashTable内部进行了归一化处理，对于index类型key同样分配了hash值和nKeyLength(为0)。内部成员变量nNextFreeElement就是当前分配到的最大id，每次push后自动加一。正是这种归一化处理，PHP才能够实现关联和非关联的混合。由于push操作的特殊性，索引key在PHP数组中先后顺序并不是通过下标大小来决定，而是由push的先后决定。例如 $arr[1] = 2; $arr[2] = 3;对于double类型的key，Zend HashTable会将他当做索引key处理 6 PHP变量PHP是一门弱类型语言，本身不严格区分变量的类型。PHP在变量申明的时候不需要指定类型。PHP在程序运行期间可能进行变量类型的隐示转换。和其他强类型语言一样，程序中也可以进行显示的类型转换。PHP变量可以分为简单类型(int、string、bool)、集合类型(array resource object)和常量(const)。以上所有的变量在底层都是同一种结构 zval。 Zval是zend中另一个非常重要的数据结构，用来标识并实现PHP变量，其数据结构如下： Zval主要由三部分组成： type：指定了变量所述的类型（整数、字符串、数组等） refcount&amp;is_ref：用来实现引用计数(后面具体介绍) value：核心部分，存储了变量的实际数据 Zvalue是用来保存一个变量的实际数据。因为要存储多种类型，所以zvalue是一个union，也由此实现了弱类型。PHP变量类型和其实际存储对应关系如下： 12345IS_LONG -&gt; lvalueIS_DOUBLE -&gt; dvalueIS_ARRAY -&gt; htIS_STRING -&gt; strIS_RESOURCE -&gt; lvalue 引用计数在内存回收、字符串操作等地方使用非常广泛。PHP中的变量就是引用计数的典型应用。Zval的引用计数通过成员变量is_ref和ref_count实现，通过引用计数，多个变量可以共享同一份数据。避免频繁拷贝带来的大量消耗。 在进行赋值操作时，zend将变量指向相同的zval同时ref_count++，在unset操作时，对应的ref_count-1。只有ref_count减为0时才会真正执行销毁操作。如果是引用赋值，则zend会修改is_ref为1。 PHP变量通过引用计数实现变量共享数据，那如果改变其中一个变量值呢？当试图写入一个变量时，Zend若发现该变量指向的zval被多个变量共享，则为其复制一份ref_count为1的zval，并递减原zval的refcount，这个过程称为“zval分离”。可见，只有在有写操作发生时zend才进行拷贝操作，因此也叫copy-on-write(写时拷贝) 对于引用型变量，其要求和非引用型相反，引用赋值的变量间必须是捆绑的，修改一个变量就修改了所有捆绑变量。 整数、浮点数是PHP中的基础类型之一，也是一个简单型变量。对于整数和浮点数，在zvalue中直接存储对应的值。其类型分别是long和double。 从zvalue结构中可以看出，对于整数类型，和c等强类型语言不同，PHP是不区分int、unsigned int、long、long long等类型的，对它来说，整数只有一种类型也就是long。由此，可以看出，在PHP里面，整数的取值范围是由编译器位数来决定而不是固定不变的。 对于浮点数，类似整数，它也不区分float和double而是统一只有double一种类型。 在PHP中，如果整数范围越界了怎么办？这种情况下会自动转换为double类型，这个一定要小心，很多trick都是由此产生。 和整数一样，字符变量也是PHP中的基础类型和简单型变量。通过zvalue结构可以看出，在PHP中，字符串是由由指向实际数据的指针和长度结构体组成，这点和c++中的string比较类似。由于通过一个实际变量表示长度，和c不同，它的字符串可以是2进制数据（包含），同时在PHP中，求字符串长度strlen是O(1)操作。 在新增、修改、追加字符串操作时，PHP都会重新分配内存生成新的字符串。最后，出于安全考虑，PHP在生成一个字符串时末尾仍然会添加\\0 常见的字符串拼接方式及速度比较： 假设有如下4个变量：$strA=‘123’; $strB = ‘456’; $intA=123; intB=456; 现在对如下的几种字符串拼接方式做一个比较和说明： 12345678$res = $strA.$strB和$res = “$strA$strB”这种情况下，zend会重新malloc一块内存并进行相应处理，其速度一般$strA = $strA.$strB这种是速度最快的，zend会在当前strA基础上直接relloc，避免重复拷贝$res = $intA.$intB这种速度较慢，因为需要做隐式的格式转换，实际编写程序中也应该注意尽量避免$strA = sprintf (“%s%s”,$strA.$strB);这会是最慢的一种方式，因为sprintf在PHP中并不是一个语言结构，本身对于格式识别和处理就需要耗费比较多时间，另外本身机制也是malloc。不过sprintf的方式最具可读性，实际中可以根据具体情况灵活选择。 PHP的数组通过Zend HashTable来天然实现。 foreach操作如何实现？对一个数组的foreach就是通过遍历hashtable中的双向链表完成。对于索引数组，通过foreach遍历效率比for高很多，省去了key-&gt;value的查找。count操作直接调用HashTable-&gt;NumOfElements，O(1)操作。对于’123’这样的字符串，zend会转换为其整数形式。$arr[‘123’]和$arr[123]是等价的 资源类型变量是PHP中最复杂的一种变量，也是一种复合型结构。 PHP的zval可以表示广泛的数据类型，但是对于自定义的数据类型却很难充分描述。由于没有有效的方式描绘这些复合结构，因此也没有办法对它们使用传统的操作符。要解决这个问题，只需要通过一个本质上任意的标识符（label）引用指针，这种方式被称为资源。 在zval中，对于resource，lval作为指针来使用，直接指向资源所在的地址。Resource可以是任意的复合结构，我们熟悉的mysqli、fsock、memcached等都是资源。 如何使用资源： *注册：对于一个自定义的数据类型，要想将它作为资源。首先需要进行注册，zend会为它分配全局唯一标示。*获取一个资源变量：对于资源，zend维护了一个id-&gt;实际数据的hash_tale。对于一个resource，在zval中只记录了它的id。fetch的时候通过id在hash_table中找到具体的值返回。*资源销毁：资源的数据类型是多种多样的。Zend本身没有办法销毁它。因此需要用户在注册资源的时候提供销毁函数。当unset资源时，zend调用相应的函数完成析构。同时从全局资源表中删除它。 资源可以长期驻留，不只是在所有引用它的变量超出作用域之后，甚至是在一个请求结束了并且新的请求产生之后。这些资源称为持久资源，因为它们贯通SAPI的整个生命周期持续存在，除非特意销毁。很多情况下，持久化资源可以在一定程度上提高性能。比如我们常见的mysql_pconnect ,持久化资源通过pemalloc分配内存，这样在请求结束的时候不会释放。对zend来说，对两者本身并不区分。 PHP中的局部变量和全局变量是如何实现的？对于一个请求，任意时刻PHP都可以看到两个符号表(symbol_table和active_symbol_table)，其中前者用来维护全局变量。后者是一个指针，指向当前活动的变量符号表，当程序进入到某个函数中时，zend就会为它分配一个符号表x同时将active_symbol_table指向a。通过这样的方式实现全局、局部变量的区分。 获取变量值：PHP的符号表是通过hash_table实现的，对于每个变量都分配唯一标识，获取的时候根据标识从表中找到相应zval返回。 函数中使用全局变量：在函数中，我们可以通过显式申明global来使用全局变量。在active_symbol_table中创建symbol_table中同名变量的引用，如果symbol_table中没有同名变量则会先创建。","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"PHP7.1 加密函数mcrypt_module_open()替换方案 和rsa pem参数细解","slug":"php_openssl","date":"2017-03-09T06:06:16.000Z","updated":"2021-11-19T03:41:15.353Z","comments":true,"path":"2017/03/09/php_openssl/","link":"","permalink":"https://anyuzhe.github.io/2017/03/09/php_openssl/","excerpt":"","text":"7.1的发布文档上面 写了以后不建义使用类似mcrypt的扩展 可以使用openssl拓展进行加密解密操作 用 OpenSSL， Linux 上自带，常用命令如下： – 生成 RSA 私钥（传统格式的） openssl genrsa -out rsa_private_key.pem 1024 – 将传统格式的私钥转换成 PKCS#8 格式的（JAVA需要使用的私钥需要经过PKCS#8编码，PHP程序不需要，可以直接略过） openssl pkcs8 -topk8 -inform PEM -in rsa_private_key.pem -outform PEM -nocrypt – 生成 RSA 公钥 openssl rsa -in rsa_private_key.pem -pubout -out rsa_public_key.pem 以下示例代码 AES: 1234567891011121314&lt;?phpheader(&apos;Content-Type: text/plain;charset=utf-8&apos;);$data = &apos;phpbest&apos;;$key = &apos;oScGU3fj8m/tDCyvsbEhwI91M1FcwvQqWuFpPoDHlFk=&apos;; //echo base64_encode(openssl_random_pseudo_bytes(32));$iv = &apos;w2wJCnctEG09danPPI7SxQ==&apos;; //echo base64_encode(openssl_random_pseudo_bytes(16));echo &apos;内容: &apos;.$data.&quot;\\n&quot;;$encrypted = openssl_encrypt($data, &apos;aes-256-cbc&apos;, base64_decode($key), OPENSSL_RAW_DATA, base64_decode($iv));echo &apos;加密: &apos;.base64_encode($encrypted).&quot;\\n&quot;;$encrypted = base64_decode(&apos;To3QFfvGJNm84KbKG1PLzA==&apos;);$decrypted = openssl_decrypt($encrypted, &apos;aes-256-cbc&apos;, base64_decode($key), OPENSSL_RAW_DATA, base64_decode($iv));echo &apos;解密: &apos;.$decrypted.&quot;\\n&quot;;?&gt; RSA:用openssl生成rsa密钥对(私钥/公钥):openssl genrsa -out rsa_private_key.pem 1024openssl rsa -pubout -in rsa_private_key.pem -out rsa_public_key.pem 123456789101112&lt;?phpheader(&apos;Content-Type: text/plain;charset=utf-8&apos;);$data = &apos;phpbest&apos;;echo &apos;原始内容: &apos;.$data.&quot;\\n&quot;;openssl_public_encrypt($data, $encrypted, file_get_contents(dirname(__FILE__).&apos;/rsa_public_key.pem&apos;));echo &apos;公钥加密: &apos;.base64_encode($encrypted).&quot;\\n&quot;;$encrypted = base64_decode(&apos;nMD7Yrx37U5AZRpXukingESUNYiSUHWThekrmRA0oD0=&apos;);openssl_private_decrypt($encrypted, $decrypted, file_get_contents(dirname(__FILE__).&apos;/rsa_private_key.pem&apos;));echo &apos;私钥解密: &apos;.$decrypted.&quot;\\n&quot;;?&gt; 秘钥可以用 openssl rsa -inform PEM -modulus -noout &lt; private_key.pem 得出详细数据 rsa总共用到的数据pqn(module)φ(n)ed 说明 PEM RSAParameterModulus modulusExponent Exponentprime1 Pexponent1 Qprime2 DPexponent2 DQcoefficient InverseQprivateExponent D 页面上行js rsa加密可以用 http://www.ohdave.com/rsa/index.php 这个 n为 openssl rsa -pubin -inform PEM -modulus -noout &lt; public_key.peme为 openssl rsa -pubin -inform PEM -text -noout &lt; public_key.pem","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"Linux上mysql开启远程连接方法","slug":"Linux上mysql开启远程连接方法","date":"2017-03-06T15:16:15.000Z","updated":"2021-11-19T03:41:15.350Z","comments":true,"path":"2017/03/06/Linux上mysql开启远程连接方法/","link":"","permalink":"https://anyuzhe.github.io/2017/03/06/Linux上mysql开启远程连接方法/","excerpt":"","text":"默认情况下，Mysql为了安全起见是不支持远程访问和连接的。不过有的时候，工作需要你要从家里或者网页来访问Mysql，本文就介绍下怎么在Linux系统上给Mysql创建一个远程连接的账户，支持远程访问. 0 首先登陆linux 1 编辑Mysql的配置文件：my.cnf 注释bind-address = 127.0.0.1 如果你的系统是Debian Linux 那文件位置是：/etc/mysql/my.cnf .如果你的系统是 Red Hat Linux/Fedora/Centos Linux 那文件位置是： /etc/my..如果你的系统是 FreeBSD 那文件位置是： /var/db/mysql/my.cnf . ps: bind-address: 绑定的IP skip-networking : 不再监听TCP/IP 连接. 所有的Mysql交互都要通过Unix sockets. 如果你只想本地请求的话强烈建议开启，因为我们现在是开启远程连接，所以在这里我们就给注释掉，在前面加上#号就可以了 2 重启mysql服务如果是Debian / Ubuntu Linux系统，输入下面的命令重启Mysql服务 /etc/init.d/mysql restart 如果是RHEL / CentOS / Fedora / Scientific Linux系统，输入下面的命令重启Mysql服务 /etc/init.d/mysqld restart 如果是FreeBSD系统，输入下面的命令重启Mysql服务 /usr/local/etc/rc.d/mysql-server stop/usr/local/etc/rc.d/mysql-server start 或者 /usr/local/etc/rc.d/mysql-server restart 3 给远程IP授权增加型 GRANT ALL ON foo.* TO bar@’202.54.10.20’ IDENTIFIED BY ‘PASSWORD’;修改型update user set host=’%’ where user=’root’ and host=’localhost’; 刷新权限 flush privileges; 4 防火墙开放3306端口1、打开防火墙配置文件 vi /etc/sysconfig/iptables 2、增加下面一行 -A INPUT -m state –state NEW -m tcp -p tcp –dport 3306 -j ACCEPT 3、重启防火墙 service iptables restart 注意：增加的开放3306端口的语句一定要在icmp-host-prohibited之前附：个人配置`# Firewall configuration written by system-config-firewall Manual customization of this file is not recommended. filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state –state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -i eth0 -j ACCEPT-A INPUT -m state –state NEW -m tcp -p tcp –dport 22 -j ACCEPT-A INPUT -m state –state NEW -m tcp -p tcp –dport 80 -j ACCEPT-A INPUT -m state –state NEW -m tcp -p tcp –dport 3306 -j ACCEPT-A FORWARD -m state –state ESTABLISHED,RELATED -j ACCEPT-A FORWARD -p icmp -j ACCEPT-A FORWARD -i lo -j ACCEPT-A FORWARD -i eth0 -j ACCEPT-A INPUT -j REJECT –reject-with icmp-host-prohibited-A FORWARD -j REJECT –reject-with icmp-host-prohibitedCOMMIT","categories":[{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://anyuzhe.github.io/tags/mysql/"}]},{"title":"编程的道术","slug":"编程的道术","date":"2017-03-04T12:06:31.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/03/04/编程的道术/","link":"","permalink":"https://anyuzhe.github.io/2017/03/04/编程的道术/","excerpt":"","text":"道是让你明白事物运作原理和流程 一、开篇 在开始这个专题之前，先说一点题外话。大多数人学习编程语言的时候，首先关注的是这种语言的语法及其常用函数。我学习C,Php等语言就是按照这样的方式开始的。一般情况下，这个阶段需要一个月左右的时间就会完全掌握，并能基本熟练地使用。对于已有经验的同学，可能时间更短。其实各种语言的语法和常用函数都差别不大，有很多相通的地方。如果您在学习一种编程语言的时候，拿一些真正的项目任务作为实践，效果更佳，实践远胜于理论。 我们在掌握了一门编程语言之后，又会向两个方向发展：一个方向是向上延伸，从事系统框架结构的探索；另一方向是向下延伸，从事系统底层方面的研究，我大体画了一下这个学习演变过程的示意图。","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"way","slug":"way","permalink":"https://anyuzhe.github.io/tags/way/"}]},{"title":"vue.js相关文档","slug":"vue相关文档","date":"2017-03-01T14:58:33.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2017/03/01/vue相关文档/","link":"","permalink":"https://anyuzhe.github.io/2017/03/01/vue相关文档/","excerpt":"","text":"尤雨溪的知乎 vue 中文文档 vuex 单一状态树 vue-resource全攻略 iView 开源的vue的组件","categories":[{"name":"vue","slug":"vue","permalink":"https://anyuzhe.github.io/categories/vue/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://anyuzhe.github.io/tags/vue/"}]},{"title":"记第一次去深圳的收获","slug":"share_shenzhen_first","date":"2017-02-26T15:06:20.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/02/26/share_shenzhen_first/","link":"","permalink":"https://anyuzhe.github.io/2017/02/26/share_shenzhen_first/","excerpt":"","text":"2017-02-26 在深圳一天目的地是laravel-china 的分享交流会 时间很短,10点到12点 实际时间好像还不到12点就结束了听了2个开发者的分享,因为分享的内容是对于laravel入门的教程,所以对我没有大的帮助 就不记录了 会中,会后和当地的php开发者交流了一下发现深圳的大多数公司的开发者和我这边的php水平差不多, 但是用户量大了N多深圳的软件公司的项目用户量都挺大的, 还有不少海外项目.因为用户量大,用到了高并发的处理技术.和涉及金钱交易, 要很低的容错率这两个内容,对于小城市工作的我是没啥经验的. (虽然,队列啥的也用过,但是人家的数据都是按t来的,而我的项目,数据库数据最多的是日志表,数据库最大的一个项目也就百来mb) 这大概就是架构师的能力 认识了一个从程序员到 7家天猫店主的土豪 铁林哥从铁林哥那里拷了一份用laravel开发一整个博客,运用tdd的开发模式进行开发.的教学视频.在空的时候看看学习一下tdd的开发模式中午吃饭的时候听到大神说typescript很好用,有空也准备看一下 回来的高铁上,同铺是一个学石油专业的研究生,交流中,表达了对小城市安逸生活的向往,在大城市每天的节奏太紧,幸福感很低他因为专业很偏,相关工作在小城市没有,只能去大城市找 让我感觉行业的重要性,软件开发还是非常不错的行业( 优点:工作相对于好找,工资提升的也快 缺点:精神上有点累) 目前应该专注于技术能力提升","categories":[{"name":"日志","slug":"日志","permalink":"https://anyuzhe.github.io/categories/日志/"}],"tags":[{"name":"share","slug":"share","permalink":"https://anyuzhe.github.io/tags/share/"}]},{"title":"项目中微信授权登录首页的过程","slug":"项目中微信授权登录首页的过程","date":"2017-02-24T07:31:58.000Z","updated":"2021-11-19T03:41:15.358Z","comments":true,"path":"2017/02/24/项目中微信授权登录首页的过程/","link":"","permalink":"https://anyuzhe.github.io/2017/02/24/项目中微信授权登录首页的过程/","excerpt":"","text":"流程1 菜单中的自动打新按钮 url 指向 微信的授权页(回调跳转设置url中附带授权code参数) 响应时间为100-318ms 进入授权页-&gt;用户需要点击确定 向微信发送确认信息 微信回调301跳转回调页 77ms如果已经授权了或者关注了公众号就直接转向zidongdaxin的回调页 2 回调页获得授权code 根据code向微信拿取access_token和openid数据 根据openid在数据库是否有昵称数据,判断是否需要获得用户数据 通过判断是否有账户设置转向的页面 回复跳转302的消息 不需要获取用户数据的 响应时间为 279-354ms 需要后的用户数据的 响应时间为 462ms-2s ps:一半时间在1s以下 偶尔有超过1s的 3 index首页 响应时间为 80ms 结论123456789因为获取用户数据 ,目前只获取一次第1步和第2步 占的时间占了居多 第1步和第2步是从微信方获取用户唯一标识的过程如果使用cookie判断 可以去掉1和2 直接去第3步中判断 如果没有cookie就转跳去第一步微信的授权页 速度会快 不过微信如果换了账号 就会造成数据错乱","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"wechat","slug":"wechat","permalink":"https://anyuzhe.github.io/tags/wechat/"}]},{"title":"安利一些好用的php包","slug":"安利一些好用的php包","date":"2017-02-23T12:05:57.000Z","updated":"2021-11-19T03:41:15.357Z","comments":true,"path":"2017/02/23/安利一些好用的php包/","link":"","permalink":"https://anyuzhe.github.io/2017/02/23/安利一些好用的php包/","excerpt":"","text":"现代化php的开发就是 运用composer生态的包进行开发 可以大大提高了开发速度 本文会更一些不依赖任何php框架的第三方开发包也就是会用composer你就能很简单的集成到项目里 payment 这是一个支付的包,封装了多种支付dsk的支付发起方法和回调验证方法,代码比较优美,实用性满分 easyweacht 安正超写的,是对微信sdk的进一步封装,微信开发中使用,实用性满分 Goutte 著名爬虫类库 国外phper很流行 更新中…请期待","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"session工作机制","slug":"session_introduce","date":"2017-02-22T15:54:39.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/02/22/session_introduce/","link":"","permalink":"https://anyuzhe.github.io/2017/02/22/session_introduce/","excerpt":"","text":"session是cookie的升级版 cookie是把信息记录在客户端,而session是把信息记录在服务器端 服务器存储信息的方式可以在内存中,可以在数据库中和文件中 过程如下 1234(1)浏览器 --&gt; 服务器 发起请求(2)浏览器 &lt;-- 服务器 响应请求 附带了setCookie 通过cookie设置了sessionid的name和值(3)浏览器 --&gt; 服务器 再次发起请求 附加了cookie数据(4)浏览器 &lt;-- 服务器 再次响应请求 因为cookie数据中附带了sessionid的name和值 所以就知道了浏览器的会话是同一次,并且不再需要设置 具体：当你第一次访问一个网站的时候,网站服务器会在响应头内加上Set-Cookie:PHPSESSID=nj1tvkclp3jh83olcn3191sjq3(php服务器),或Set-Cookie JSESSIONID=nj1tvkclp3jh83olcn3191sjq3(java服务器)信息,此信息是服务器随机生成的,放在服务器内存里,为了标识唯一的客户端用户,内容不会重复,这就是sessionid.该Cookie为服务器自动生成的，它的maxAge属性一般为-1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。因此同一机器的两个浏览器窗口访问服务器时，会生成两个不同的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击桌面浏览器图标等打开的窗口）除外。这类子窗口会共享父窗口的Cookie，因此会共享一个Session。 所以理论上有了cookie功能,就一定可以有session功能.如果没有cookie功能的话,也可以通过url传参的方式,使得session仍旧可以实现 php内置了的session功能 并且有一个$_SESSION的全局数组存入或读取数组 还会自动把数据存入文件session配置在php.ini文件中可以修改 很多框架已经重写了php默认的session处理机制,达到加密的效果 ps:在tp3.23中增加了session的配置项,但默认是php的默认设置,所以安全性存在问题,目前会被微信浏览器禁用","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"临时信息储存","slug":"temp_data","date":"2017-02-16T15:50:19.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2017/02/16/temp_data/","link":"","permalink":"https://anyuzhe.github.io/2017/02/16/temp_data/","excerpt":"","text":"git log –graph –pretty=oneline –abbrev-commit //比较好看的git log指令 深入浅出讲解：php的socket通信 js实现base64转码 youzan/zanui-weapp 微信小程序开发资源汇总 Python Cookbook中文版","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"temp","slug":"temp","permalink":"https://anyuzhe.github.io/tags/temp/"}]},{"title":"unicode,ansi,utf-8,unicode big endian编码的区别","slug":"utf8_unicode_explain","date":"2017-02-15T12:00:05.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2017/02/15/utf8_unicode_explain/","link":"","permalink":"https://anyuzhe.github.io/2017/02/15/utf8_unicode_explain/","excerpt":"","text":"很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们看到8个开关状态是好的，于是他们把这称为”字节”。 再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机”。 开始计算机只在美国用。八位的字节一共可以组合出256(2的8次方)种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端、打印机遇上约定好的这些字节被传过来时，就要做一些约定的动作。遇上00x10, 终端就换行，遇上0x07, 终端就向人们嘟嘟叫，例好遇上0x1b, 打印机就打印反白的字，或者终端就用彩色显示字母。他们看到这样很好，于是就把这些0x20以下的字节状态称为”控制码”。 他们又把所有的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉很好，于是大家都把这个方案叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。 后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们的字母里有许多是ASCII里没有的，为了可以在计算机保存他们的文字，他们决定采用127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128到255这一页的字符集被称”扩展字符集”。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！ 等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉, 规定：一个小于127的字符的意义与原来相同，但两个大 于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 中国人民看到这样很不错，于是就把这种汉字方案叫做 “GB2312”。GB2312 是对 ASCII 的中文扩展。 但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是某些很会麻烦别人的国家领导人。于是我们不得不继续把 GB2312 没有用到的码位找出来老实不客气地用上。 后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK 包括了 GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，GBK 扩成了 GB18030。从此之后，中华民族的文化就可以在计算机时代中传承了。 中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS”（Double Byte Charecter Set 双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加持，会编程的计算机僧侣们都要每天念下面这个咒语数百遍： “一个汉字算两个英文字符！一个汉字算两个英文字符……” 因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，谁也不支持别人的编码，连大陆和台湾这样只相隔了150海里，使用着同一种语言的兄弟地区，也分别采用了不同的 DBCS 编码方案——当时的中国人想让电脑显示汉字，就必须装上一个”汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士写的算命程序就必须加装另一套支持 BIG5 编码的什么”倚天汉字系统”才可以用，装错了字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷苦人民，他们的文字又怎么办？ 真是计算机的巴比 伦塔命题啊！ 正在这时，大天使加百列及时出现了——一个叫 ISO （国际标谁化组织）的国际组织决定着手解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “UNICODE”。 UNICODE 开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是 ISO 就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于ascii里的那些“半角”字符，UNICODE 包持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。 这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的strlen函数靠不住了，一个汉字不再是相当于两个字符了，而是一个！是的，从 UNICODE 开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的”一个字符”！同时，也都是统一的”两个字节”，请注意”字符”和”字节”两个术语的不同，“字节”是一个8位的物理存贮单元，而“字符”则是一个文化相关的符号。在UNICODE 中，一个字符就是两个字节。一个汉字算两个英文字符的时代已经快过去了。 从前多种字符集存在时，那些做多语言软件的公司遇上过很大麻烦，他们为了在不同的国家销售同一套软件，就不得不在区域化软件时也加持那个双字节字符集咒语，不仅要处处小心不要搞错，还要把软件中的文字在不同的字符集中转来转去。UNICODE 对于他们来说是一个很好的一揽子解决方案，于是从 Windows NT 开始，MS 趁机把它们的操作系统改了一遍，把所有的核心代码都改成了用 UNICODE 方式工作的版本，从这时开始，WINDOWS 系统终于无需要加装各种本土语言系统，就可以显示全世界上所有文化的字符了。 但是，UNICODE 在制订时没有考虑与任何一种现有的编码方案保持兼容，这使得 GBK 与UNICODE 在汉字的内码编排上完全是不一样的，没有一种简单的算术方法可以把文本内容从UNICODE编码和另一种编码进行转换，这种转换必须通过查表来进行。 如前所述，UNICODE 是用两个字节来表示为一个字符，他总共可以组合出65535不同的字符，这大概已经可以覆盖世界上所有文化的符号。如果还不够也没有关系，ISO已经准备了UCS-4方案，说简单了就是四个字节来表示一个字符，这样我们就可以组合出21亿个不同的字符出来（最高位有其他用途），这大概可以用到银 河联邦成立那一天吧！ UNICODE 来到时，一起到来的还有计算机网络的兴起，UNICODE 如何在网络上传输也是一个必须考虑的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，UTF8就是每次8个位传输数据，而UTF16就是每次16个位，只不过为了传输时的可靠性，从UNICODE到UTF时并不是直接的对应，而是要过一些算法和规则来转换。 受到过网络编程加持的计算机僧侣们都知道，在网络里传递信息时有一个很重要的问题，就是对于数据高低位的解读方式，一些计算机是采用低位先发送的方法，例如我们PC机采用的 INTEL 架构，而另一些是采用高位先发送的方式，在网络中交换数据时，为了核对双方对于高低位的认识是否是一致的，采用了一种很简便的方法，就是在文本流的开始时向对方发送一个标志符——如果之后的文本是高位在位，那就发送”FEFF”，反之，则发送”FFFE”。不信你可以用二进制方式打开一个UTF-X格式的文件，看看开头两个字节是不是这两个字节？ 讲到这里，我们再顺便说说一个很著名的奇怪现象：当你在 windows 的记事本里新建一个文件，输入”联通”两个字之后，保存，关闭，然后再次打开，你会发现这两个字已经消失了，代之的是几个乱码！呵呵，有人说这就是联通之所以拼不过移动的原因。 其实这是因为GB2312编码与UTF8编码产生了编码冲撞的原因。 从网上引来一段从UNICODE到UTF8的转换规则： Unicode UTF-8 0000 - 007F 0xxxxxxx 0080 - 07FF 110xxxxx 10xxxxxx 0800 - FFFF 1110xxxx 10xxxxxx 10xxxxxx 例如”汉”字的Unicode编码是6C49。6C49在0800-FFFF之间，所以要用3字节模板：1110xxxx 10xxxxxx 10xxxxxx。将6C49写成二进制是：0110 1100 0100 1001，将这个比特流按三字节模板的分段方法分为0110 110001 001001，依次代替模板中的x，得到：1110-0110 10-110001 10-001001，即E6 B1 89，这就是其UTF8的编码。 而当你新建一个文本文件时，记事本的编码默认是ANSI, 如果你在ANSI的编码输入汉字，那么他实际就是GB系列的编码方式，在这种编码下，”联通”的内码是： c1 1100 0001 aa 1010 1010 cd 1100 1101 a8 1010 1000 注意到了吗？第一二个字节、第三四个字节的起始部分的都是”110”和”10”，正好与UTF8规则里的两字节模板是一致的，于是再次打开记事本时，记事本就误认为这是一个UTF8编码的文件，让我们把第一个字节的110和第二个字节的10去掉，我们就得到了”00001 101010”，再把各位对齐，补上前导的0，就得到了”0000 0000 0110 1010”，不好意思，这是UNICODE的006A，也就是小写的字母”j”，而之后的两字节用UTF8解码之后是0368，这个字符什么也不是。这就是只有”联通” 两个字的文件没有办法在记事本里正常显示的原因。 而如果你在”联通”之后多输入几个字，其他的字的编码不见得又恰好是110和10开始的字节，这样再次打开时，记事本就不会坚持这是一个utf8编码的文件，而会用ANSI的方式解读之，这时乱码又不出现了。 好了，终于可以回答NICO的问题了，在数据库里，有n前缀的字串类型就是UNICODE类型，这种类型中，固定用两个字节来表示一个字符，无论这个字符是汉字还是英文字母，或是别的什么。 如果你要测试”abc汉字”这个串的长度，在没有n前缀的数据类型里，这个字串是7个字符的长度，因为一个汉字相当于两个字符。而在有n前缀的数据类型里，同样的测试串长度的函数将会告诉你是5个字符，因为一个汉字就是一个字符。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://anyuzhe.github.io/categories/计算机基础/"}],"tags":[{"name":"computer","slug":"computer","permalink":"https://anyuzhe.github.io/tags/computer/"}]},{"title":"博客社区文章推荐 长期更新~","slug":"share_good_data_url","date":"2017-02-15T06:53:22.000Z","updated":"2021-11-19T03:41:15.355Z","comments":true,"path":"2017/02/15/share_good_data_url/","link":"","permalink":"https://anyuzhe.github.io/2017/02/15/share_good_data_url/","excerpt":"","text":"知乎 v2ex等 一些大型站点 不在推荐范围内 名人的博客阮一峰的网络日志 非常著名的博客,有着很多前端技术和计算机基础的文章 惠新宸(鸟哥)的个人站点 PHP开发组核心成员, Zend顾问, PHP7主要开发者, Yaf, Yar, Yac等开源项目作者 廖雪峰的个人网站 比较详细的js python git教程 干货博客博客名:上善若水 一些简单的管理和敏捷的知识 小谈博客 一个专注现代化PHP开发的博客 周继平的博客 最近出了一些laravel的干货,类似于学习笔记 zhangxinrun的专栏 啥语言都有,海量的文章,不过有点旧了,看基础不错 进击的Java新人 一个java大牛的分享博客 2017php学习路线图 很全 php重要社区laravel学院 看名字就知道都是关于laravel的教程,文章基本上都是站长学院君发的 laravel教程视频站 关于laravel的教学视频站,都是站长(JellyBool )一个人做的,视频质量高于慕课网,自认为是目前国内最好的laravel视频教程(收费) laravel-china社区 非官方社区,是一堆laravel爱好者的集中地 活跃度和水平高于别的php-laravel相关的社区(可能也是php的)","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"centos 编译安装php","slug":"centos编译安装php","date":"2017-02-14T06:35:09.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2017/02/14/centos编译安装php/","link":"","permalink":"https://anyuzhe.github.io/2017/02/14/centos编译安装php/","excerpt":"","text":"个人还是更喜欢使用Ubuntu apt-get官方源更新的比较快 基本与php新版本同步 而在centos中官方源的php版本严重停滞 所以需要编译安装php 下面是安装流程同时学习开发php扩展之前必须先学会php的编译安装,php扩展开发可以使得php使用c里面写的函数,和c++里定义的类,使得php更加强大 首先在php官网下载 php的源码包php国内官网 cd 进入源码包 —安装php的依赖包— yum install epel-release //扩展包更新包yum update //更新yum源yum install libmcrypt libmcrypt-devel mcrypt mhashyum install -y libxml2 libxml2-devel openssl openssl-devel libcurl-devel libjpeg-devel libpng-devel libicu-devel openldap-devel —编译和安装—./configure 帮你创建Makefile文件 ./configure –prefix=/usr/local/php56 –with-config-file-path=/usr/local/php56/etc –enable-fpm –with-fpm-user=www –with-fpm-group=www –enable-mysqlnd –with-mysql=mysqlnd –with-mysqli=mysqlnd –with-pdo-mysql=mysqlnd –enable-opcache –enable-mbstring –enable-soap –enable-zip –enable-bcmath –with-openssl –with-zlib –with-curl –with-gd –with-zlib-dir=/usr/lib –with-png-dir=/usr/lib –with-jpeg-dir=/usr/lib –with-mhash –with-mcrypt 参数说明 “”” 安装路径 “””–prefix=/usr/local/php56 “”” php.ini 配置文件路径 “””–with-config-file-path=/usr/local/php56/etc “”” 优化选项 “””–enable-inline-optimization –disable-debug –disable-rpath –enable-shared “”” 启用 opcache，默认为 ZendOptimizer+(ZendOpcache) “””–enable-opcache “”” FPM “””–enable-fpm –with-fpm-user=www –with-fpm-group=www “”” MySQL “””–with-mysql=mysqlnd –with-mysqli=mysqlnd –with-pdo-mysql=mysqlnd “”” 国际化与字符编码支持 “””–with-gettext –enable-mbstring –with-iconv “”” 加密扩展 “””–with-mcrypt –with-mhash –with-openssl “”” 数学扩展 “””–enable-bcmath “”” Web 服务，soap 依赖 libxml “””–enable-soap –with-libxml-dir “”” 进程，信号及内存 “””–enable-pcntl –enable-shmop –enable-sysvmsg –enable-sysvsem –enable-sysvshm “”” socket &amp; curl “””–enable-sockets –with-curl “”” 压缩与归档 “””–with-zlib –enable-zip –with-bz2 “”” GNU Readline 命令行快捷键绑定 “””–with-readline 编译和安装 make &amp;&amp; make install 配置 PHP配置文件： cp php.ini-development /usr/local/php/etc/php.ini php-fpm 服务: cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.confcp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm 启动 php-fpm service php-fpm startStarting php-fpm done 添加 PHP 命令到环境变量编辑 ~/.bash_profile，将： PATH=$PATH:$HOME/bin改为：PATH=$PATH:$HOME/bin:/usr/local/php/bin 使 PHP 环境变量生效： source .bash_profile 三，安装PHP扩展 生成redis.so:复制代码 123456789unzip phpredis-Versioncd phpredis-Version/usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; make install 复制代码 将extension=redis.so加入到php.ini 重启服务器，查看phpinfo(); 如果是使用php-fpm，则需要重启php-fpm: ps aux|grep php-fpm #查看fpm进程号 kill -USR2 fpm进程号 #平滑重启php-fpm","categories":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/categories/php/"}],"tags":[{"name":"php","slug":"php","permalink":"https://anyuzhe.github.io/tags/php/"}]},{"title":"C++ 学习日志","slug":"c++学习日志","date":"2017-02-13T15:26:46.000Z","updated":"2021-11-19T03:41:15.351Z","comments":true,"path":"2017/02/13/c++学习日志/","link":"","permalink":"https://anyuzhe.github.io/2017/02/13/c++学习日志/","excerpt":"","text":"C和C++,是很多程序员必修之课C作为编写操作系统的语言 速度是高级语言里最快的C能直接操作内存,学习的途中可以加深对计算机运行时候,内存管理的理解C++可以更快速的编写C的工作的代码,是写了很多软件的语言 基础命名空间 命名空间可以防止,两个类的成员和方法命名冲突 可以使用using关键字,来引入命名空间 例如：using namespace std; 别名 可以在函数的形参中在变量前加 &amp; ,使得实参的传入变成实参取别名的方式传入,可以直接对原来的数据就行修改,对比同样方式的指针操作 更直观 定义常量的方式const 可以在函数的形参中在变量前加const 关键字,使得传入的形参变成常量,无法进行修改.也可以在指针前加关键字,使得指针无法修改为别的地址 函数重载 函数重载是指在同一作用域内，可以有一组具有相同函数名，不同参数列表的函数，这组函数被称为重载函数。重载函数通常用来命名一组功能相似的函数，这样做减少了函数名的数量，避免了名字空间的污染，对于程序的可读性有很大的好处。可以定义多个同名函数,函数参数,类型和默认值的不同进行重载 普通函数和内联函数 普通函数运行时的数据在栈里,而内联函数直接编译在代码段里 在函数前面加上关键字inline定义 但是只能定义简单逻辑的函数 内存的申请和删除 使用关键字 new delete 运算符 操作 操作的内存数据在堆中,申请的内存需要手动释放,不然会造成内存泄漏 列如:int *p = new int; delete p; 对象 三大特性 封装–继承–多态–封装–特性构造函数 与类同名的函数 在创建对象时候自动调用 析构函数 在类名前面加上~符号的函数 在销毁对象的时候自动调用 拷贝构造函数 与构造函数的函数名相同,形参不同 列如 CExample(const CExample&amp; C) 拷贝构造函数是一种特殊的构造函数，函数的名称必须和类名称一致，它必须的一个参数是本类型的一个引用变量 在C++中，下面三种对象需要调用拷贝构造函数！ 对象以值传递的方式传入函数参数 对象以值传递的方式从函数返回 对象需要通过另外一个对象进行初始化； 浅拷贝就是拷贝构造函数没有处理静态数据成员,只对对象中的数据成员进行简单的赋值深拷贝是把静态数据成员,创建新的数据对象在新的对象中传入 通过对对象复制的分析，我们发现对象的复制大多在进行“值传递”时发生，这里有一个小技巧可以防止按值传递——声明一个私有拷贝构造函数。甚至不必去定义这个拷贝构造函数，这样因为拷贝构造函数是私有的，如果用户试图按值传递或函数返回该类对象，将得到一个编译错误，从而可以避免按值传递或返回对象。 初始化列表Test2(Test1 &amp;t1):test1(t1){}构造函数的执行可以分成两个阶段，初始化阶段和计算阶段，初始化阶段先于计算阶段。 以下几种情况时必须使用初始化列表 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面 没有默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化。 –继承–特性 三种类型: 公有继承 public 保护继承 protected 私有继承 private继承的数据相同,成员访问限定符可以降级 public继承不变 protected使得public变成protected private继承使得所有成员变为private 父类的private成员不会被继承 隐藏 在子类中定义与父类的同名方法 可以使得父类的方法隐藏 然后可以用parent::function命 的形式调用 多继承与多重继承 子类同时可以继承多个父类(多继承),也可以进行多级的继承(多重继承) 虚继承 为了解决从不同途径继承来的同名的数据成员在内存中有不同的拷贝造成数据不一致问题，将共同基类设置为虚基类。这时从不同的路径继承过来的同名数据成员在内存中就只有一个拷贝，同一个函数名也只有一个映射。这样不仅就解决了二义性问题，也节省了内存，避免了数据不一致的问题。class 派生类名：virtual 继承方式 基类名virtual是关键字，声明该基类为派生类的虚基类。在多继承情况下，虚基类关键字的作用范围和继承方式关键字相同，只对紧跟其后的基类起作用。声明了虚基类之后，虚基类在进一步派生过程中始终和派生类一起，维护同一个基类子对象的拷贝。 –多态–特性虚函数子类继承使用虚函数进行函数的覆盖 态类型：具有继承关系的多个类型知识点1：虚函数(virtual 函数名();)——解决“如果你以一个基类指针指向一个派生类对象，那么通过该指针，你只能访问基础类定义的成员函数”此问题。原因：如果你以一个基类指针指向一个派生类对象，那么通过该指针，你只能访问基础类定义的成员函数；如果以派生类指针指向基类对象，这种做法相当危险，一般不会这么定义知识点2：同名成员函数——如果基类和派生类定义了相同的成员函数，那么对象指针调用成员函数时，到底调用的是哪个成员函数，最终取决于这个指针的原型，而不是指向的对象类型，不过虚函数可以解决此问题，可以在“一个基类指针指向一个派生类对象”的情况下，调用派生类对象的同名成员函数知识点3：虚析构函数(virtual ~类名();)——解决在动态多态中，内存泄漏的问题知识点4：virtual限制用法——不能修饰类外申明并定义的函数（全局函数），即只能修饰类内申明并定义的函数（通常在申明时修饰即可）；virtual不能修饰类内的静态成员函数；virtual不能修饰内联函数；virtual不能修饰构造函数。知识点5：继承虚函数——注意上述，虚函数和虚析构函数，一定要在基类里给函数或者析构函数添加virtual关键字。若基类里，申明虚函数，则派生类里会默认继承虚函数，当然最好也给其他类加上virtual关键字注：在C++11新标准中，可以使用override关键字来说明派生类中的虚函数。知识点6：析构函数最好都添加virtual关键字，使之成为虚析构函数，这样避免之后出现的内存泄漏问题（即内存占用不释放），因为并不知道未来继承的子类会不会在其构造函数中申请内存知识点7：虚函数原理指针指向对象——对象指针；指针指向函数——函数指针申明基类的虚函数时，会自动生成虚函数表，用于寻找虚函数的入口地址，如果派生类继承基类的虚函数，且没有自定义同名虚函数时，则也会自动生成虚函数表，而自动生成的虚函数表指针，会指向基类虚函数的相同入口地址；但如果派生类继承基类，并自定义同名虚函数时，则会自动生成虚函数，但指向与上述不同的虚函数入口地址（函数的覆盖）。知识点8：函数的覆盖和隐藏当基类和子类出现同名函数时，此时出现函数的隐藏；但若定义了虚同名函数，则此时出现函数的覆盖。（可参考知识点7，即虚函数表的地址异同问题）知识点9：虚析构函数原理理论前提：执行完派生类的析构函数就会执行基类的析构函数当在基类中，申明虚析构函数后，则在派生类中，也会在默认生成虚析构函数，即在派生类的析构函数前，默认加上virtual关键字这样可以解决内存泄漏问题，即解决了“释放了指向基类对象的指针所占内存，但忘了释放派生类里分配给另一指针的内存（假如另一指针存在的话）”，因为派生类的虚函数指针表的作用（请参考知识点7)，结果就是先执行派生类的析构函数，再执行基类的析构函数，从而无内存占用，解决内存泄漏问题。知识点10：对象大小（sizeof(对象名)）这表明对象中的数据成员占用的内存大小，并不包含成员函数；若对象中，无数据成员，则默认分配其一个字节内存大小（若包含虚函数或虚析构函数，则生成虚函数表，此时占用4个字节的内存，即虚函数表指针的大小）。注：一个指针所占用4个字节的内存知识点11：虚函数表a.当类中定义了虚函数或者虚析构函数时，则在类实例化对象时，自动生成虚函数表，并在对象中生成一个虚函数表指针b.在多态的情况下，虚函数表指针在对象中所占据的内存位置是对象前4个寄存内存单元，后面排列的是其它数据成员c.每个类只有一份虚函数表，所有该类的对象共用同一张虚函数表 运行时类型识别 通过RTTI，能够通过基类的指针或引用来检索其所指对象的实际类型。c++通过下面两个操作符提供RTTI。（1）typeid：返回指针或引用所指对象的实际类型。（2）dynamic_cast：将基类类型的指针或引用安全的转换为派生类型的指针或引用。对于带虚函数的类，在运行时执行RTTI操作符，返回动态类型信息；对于其他类型，在编译时执行RTTI，返回静态类型信息。 纯虚函数 virtual 函数类型 函数名（）=0；//纯虚函数只有函数申明，没有函数定义的函数也是纯虚函数。 抽象类 定义：含有纯虚函数的类叫做抽象类抽象类无法实例化对象；抽象类的子类也可以是抽象类，但子类若将抽象类的所有函数都做了实现，即内部有程序，则子类可以实例化对象。如果一个类含有纯虚函数（抽象类），则无法实例化；但子类可以实例化对象 接口类 定义：仅含有纯虚函数的类（即无任何数据成员，仅含纯虚函数）用法：定义一个基类，作为接口类，用接口类指针指向其派生类的对象，借此可以调用派生类的同名虚函数（在接口类中是纯虚函数，在派生类中是虚函数），提现接口的作用。扩展：接口类也是抽象类；不能用接口类实例化对象（即接口类可以被继承，但不可实例化对象）；一个类既可以继承一个或多个接口类，也可以同时继承非接口类；可以使用接口类指针指向其子类对象，并调用子类对象中实现的接口类纯虚函数。 static静态成员 保存在类中的数据只有一份,在对象中通用,与全局变量类似 友元函数 可以在类中定义全局友元函数 和类友元函数 定义之后 可以在函数中调用类的所有成员 运算符重载 可以在类中定义运算符重载函数 来支持运算符可以进行类的运算 包括一元运算符和二元运算符 模板函数和模板类 对于运算过程不变类型变换的函数和类 可以分别使用模板函数和模板类 C++标准模板类STL 是C++中编译器实现的内置容器类vector向量 list链表 map映射等可以配合迭代器使用","categories":[{"name":"c++","slug":"c","permalink":"https://anyuzhe.github.io/categories/c/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://anyuzhe.github.io/tags/C/"}]},{"title":"Git 在团队中的最佳实践--如何正确使用Git Flow","slug":"使用gitFlow","date":"2017-02-13T06:39:46.000Z","updated":"2021-11-19T03:41:15.356Z","comments":true,"path":"2017/02/13/使用gitFlow/","link":"","permalink":"https://anyuzhe.github.io/2017/02/13/使用gitFlow/","excerpt":"","text":"Git的优点Git的优点很多，但是这里只列出我认为非常突出的几点。 由于是分布式，所有本地库包含了远程库的所有内容。 优秀的分支模型，打分支以及合并分支，机器方便。 快速，在这个时间就是金钱的时代，Git由于代码都在本地，打分支和合并分支机器快速，使用个SVN的能深刻体会到这种优势。 感兴趣的，可以去看一下Git本身的设计，内在的架构体现了很多的优势，不愧是出资天才程序员Linus (Linux之父) 之手 版本管理的挑战虽然有这么优秀的版本管理工具，但是我们面对版本管理的时候，依然有非常大得挑战，我们都知道大家工作在同一个仓库上，那么彼此的代码协作必然带来很多问题和挑战，如下： 如何开始一个Feature的开发，而不影响别的Feature？ 由于很容易创建新分支，分支多了如何管理，时间久了，如何知道每个分支是干什么的？ 哪些分支已经合并回了主干？ 如何进行Release的管理？开始一个Release的时候如何冻结Feature, 如何在Prepare Release的时候，开发人员可以继续开发新的功能？ 线上代码出Bug了，如何快速修复？而且修复的代码要包含到开发人员的分支以及下一个Release? 大部分开发人员现在使用Git就只是用三个甚至两个分支，一个是Master, 一个是Develop, 还有一个是基于Develop打得各种分支。这个在小项目规模的时候还勉强可以支撑，因为很多人做项目就只有一个Release, 但是人员一多，而且项目周期一长就会出现各种问题。 Git Flow就像代码需要代码规范一样，代码管理同样需要一个清晰的流程和规范Vincent Driessen 同学为了解决这个问题提出了 A Successful Git Branching Model下面是Git Flow的流程图 上面的图你理解不了？ 没关系，这不是你的错，我觉得这张图本身有点问题，这张图应该左转90度，大家应该就很用以理解了。 Git Flow常用的分支 Production 分支 也就是我们经常使用的Master分支，这个分支最近发布到生产环境的代码，最近发布的Release， 这个分支只能从其他分支合并，不能在这个分支直接修改 Develop 分支 这个分支是我们是我们的主开发分支，包含所有要发布到下一个Release的代码，这个主要合并与其他分支，比如Feature分支 Feature 分支 这个分支主要是用来开发一个新的功能，一旦开发完成，我们合并回Develop分支进入下一个Release Release分支 当你需要一个发布一个新Release的时候，我们基于Develop分支创建一个Release分支，完成Release后，我们合并到Master和Develop分支 Hotfix分支 当我们在Production发现新的Bug时候，我们需要创建一个Hotfix, 完成Hotfix后，我们合并回Master和Develop分支，所以Hotfix的改动会进入下一个Release Git Flow如何工作初始分支所有在Master分支上的Commit应该Tag Feature 分支分支名 feature/* Feature分支做完后，必须合并回Develop分支, 合并完分支后一般会删点这个Feature分支，但是我们也可以保留 Release分支分支名 release/* Release分支基于Develop分支创建，打完Release分之后，我们可以在这个Release分支上测试，修改Bug等。同时，其它开发人员可以基于开发新的Feature (记住：一旦打了Release分支之后不要从Develop分支上合并新的改动到Release分支) 发布Release分支时，合并Release到Master和Develop， 同时在Master分支上打个Tag记住Release版本号，然后可以删除Release分支了。 维护分支 Hotfix分支名 hotfix/* hotfix分支基于Master分支创建，开发完后需要合并回Master和Develop分支，同时在Master上打一个tag Git Flow代码示例a. 创建develop分支 12git branch developgit push -u origin develop b. 开始新Feature开发 12345678git checkout -b some-feature develop# Optionally, push branch to origin:git push -u origin some-feature # 做一些改动 git statusgit add some-filegit commit c. 完成Feature 123456789git pull origin developgit checkout developgit merge --no-ff some-featuregit push origin developgit branch -d some-feature# If you pushed branch to origin:git push origin --delete some-feature d. 开始Relase 1234git checkout -b release-0.1.0 develop# Optional: Bump version number, commit# Prepare release, commit e. 完成Release 12345678910111213141516git checkout mastergit merge --no-ff release-0.1.0git pushgit checkout developgit merge --no-ff release-0.1.0git pushgit branch -d release-0.1.0# If you pushed branch to origin:git push origin --delete release-0.1.0 git tag -a v0.1.0 mastergit push --tags f. 开始Hotfix 1git checkout -b hotfix-0.1.1 master g. 完成Hotfix 12345678910111213git checkout mastergit merge --no-ff hotfix-0.1.1git pushgit checkout developgit merge --no-ff hotfix-0.1.1git pushgit branch -d hotfix-0.1.1git tag -a v0.1.1 mastergit push --tags","categories":[{"name":"git","slug":"git","permalink":"https://anyuzhe.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://anyuzhe.github.io/tags/git/"}]}]}